{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca74029a",
   "metadata": {},
   "source": [
    "# Formal Concept Analysis Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17580300",
   "metadata": {},
   "source": [
    "## User Guide\n",
    "\n",
    "### First of all\n",
    "Run blocks from 1 to 8 sequentially.\n",
    "\n",
    "### Quick Start\n",
    "Create a formal context defining which object has which property, e.g. from a simple ASCII-art style cross-table with object rows and property columns or from dict using **fromstring** or **fromdict**.\n",
    "\n",
    "To query common properties of objects or common objects of properties (derivation) use **intension** and  **extension**.\n",
    "\n",
    "Get the closest matching objects-properties pair of objects or properties (formal concepts) with **your_context[list of objects or properties]**\n",
    "\n",
    "Make a Graphviz visualization of the lattice - use .graphviz(view=True) to directly render it and display the resulting PDF.\n",
    "\n",
    "### See also\n",
    "\n",
    "The implementation is based on these Python packages:\n",
    "- bitsets – Ordered subsets over a predefined domain\n",
    "- graphviz – Simple Python interface for Graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1290c766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import typing\n",
    "import operator\n",
    "import fractions\n",
    "import functools\n",
    "import heapq\n",
    "import bitsets\n",
    "import graphviz\n",
    "\n",
    "from itertools import permutations, groupby, starmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07277507",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lazyproperty:\n",
    "    \"\"\"Non-data descriptor caching the computed result as instance attribute.\n",
    "    >>> class Spam(object):\n",
    "    ...     @lazyproperty\n",
    "    ...     def eggs(self):\n",
    "    ...         return 'spamspamspam'\n",
    "    >>> spam=Spam(); spam.eggs\n",
    "    'spamspamspam'\n",
    "    >>> spam.eggs='eggseggseggs'; spam.eggs\n",
    "    'eggseggseggs'\n",
    "    >>> Spam().eggs\n",
    "    'spamspamspam'\n",
    "    >>> Spam.eggs  # doctest: +ELLIPSIS\n",
    "    <...lazyproperty object at 0x...>\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, fget):\n",
    "        self.fget = fget\n",
    "        for attr in ('__module__', '__name__', '__doc__'):\n",
    "            setattr(self, attr, getattr(fget, attr))\n",
    "\n",
    "    def __get__(self, instance, owner):\n",
    "        if instance is None:\n",
    "            return self\n",
    "        result = instance.__dict__[self.__name__] = self.fget(instance)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e73ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vector = bitsets.bases.MemberBits\n",
    "\"\"\"Single row or column of a boolean matrix as bit vector.\"\"\"\n",
    "\n",
    "\n",
    "class Vectors(bitsets.series.Tuple):\n",
    "    \"\"\"Paired collection of rows or columns of a boolean matrix relation.\n",
    "    Trailing zeros see https://stackoverflow.com/q/63917579/3456664\n",
    "    \"\"\"\n",
    "\n",
    "    def _pair_with(self, relation, index, other):\n",
    "        if hasattr(self, 'prime'):\n",
    "            raise RuntimeError(f'{self!r} attempt _pair_with {other!r}')\n",
    "\n",
    "        self.relation = relation\n",
    "        self.relation_index = index\n",
    "\n",
    "        Prime = other.BitSet.supremum\n",
    "        Double = self.BitSet.supremum\n",
    "\n",
    "        make_prime = other.BitSet.fromint\n",
    "        make_double = self.BitSet.fromint\n",
    "\n",
    "        def prime(bitset):\n",
    "            \"\"\"FCA derivation operator (extent->intent, intent->extent).\"\"\"\n",
    "            prime = Prime\n",
    "\n",
    "            i = 0\n",
    "            while bitset:\n",
    "                shift = (bitset & -bitset).bit_length() - 1  # trailing zero(s)\n",
    "                if not shift:\n",
    "                    shift = 1\n",
    "                    prime &= other[i]\n",
    "                i += shift\n",
    "                bitset >>= shift\n",
    "\n",
    "            return make_prime(prime)\n",
    "\n",
    "        def double(bitset):\n",
    "            \"\"\"FCA double derivation operator (extent->extent, intent->intent).\"\"\"\n",
    "            prime = Prime\n",
    "\n",
    "            i = 0\n",
    "            while bitset:\n",
    "                shift = (bitset & -bitset).bit_length() - 1\n",
    "                if not shift:\n",
    "                    shift = 1\n",
    "                    prime &= other[i]\n",
    "                i += shift\n",
    "                bitset >>= shift\n",
    "\n",
    "            double = Double\n",
    "\n",
    "            i = 0\n",
    "            while prime:\n",
    "                shift = (prime & -prime).bit_length() - 1\n",
    "                if not shift:\n",
    "                    shift = 1\n",
    "                    double &= self[i]\n",
    "                i += shift\n",
    "                prime >>= shift\n",
    "\n",
    "            return make_double(double)\n",
    "\n",
    "        def doubleprime(bitset):\n",
    "            \"\"\"FCA single and double derivation (extent->extent+intent, intent->intent+extent).\"\"\"\n",
    "            prime = Prime\n",
    "\n",
    "            i = 0\n",
    "            while bitset:\n",
    "                shift = (bitset & -bitset).bit_length() - 1\n",
    "                if not shift:\n",
    "                    shift = 1\n",
    "                    prime &= other[i]\n",
    "                i += shift\n",
    "                bitset >>= shift\n",
    "\n",
    "            bitset = prime\n",
    "            double = Double\n",
    "\n",
    "            i = 0\n",
    "            while bitset:\n",
    "                shift = (bitset & -bitset).bit_length() - 1\n",
    "                if not shift:\n",
    "                    shift = 1\n",
    "                    double &= self[i]\n",
    "                i += shift\n",
    "                bitset >>= shift\n",
    "\n",
    "            return make_double(double), make_prime(prime)\n",
    "\n",
    "        self.prime = self.BitSet.prime = prime\n",
    "        self.double = self.BitSet.double = double\n",
    "        self.doubleprime = self.BitSet.doubleprime = doubleprime\n",
    "\n",
    "    def __reduce__(self):\n",
    "        return self.relation, (self.relation_index,)\n",
    "\n",
    "\n",
    "class Relation(tuple):\n",
    "    \"\"\"Binary relation as interconnected pair of bitset collections.\n",
    "    >>> br = Relation('Condition', 'Symbol',\n",
    "    ... ('TT', 'TF', 'FT', 'FF'), ('->', '<-'),\n",
    "    ... [(True, False, True, True), (True, True, False, True)])\n",
    "    >>> br\n",
    "    <Relation(ConditionVectors('1011', '1101'), SymbolVectors('11', '01', '10', '11'))>\n",
    "    >>> br[1].BitSet.frommembers(('->', '<-')).prime().members()\n",
    "    ('TT', 'FF')\n",
    "    \"\"\"\n",
    "\n",
    "    __slots__ = ()\n",
    "\n",
    "    def __new__(cls, xname, yname, xmembers, ymembers, xbools, _ids=None):\n",
    "        if _ids is not None:\n",
    "            xid, yid = _ids\n",
    "            X = bitsets.meta.bitset(xname, xmembers, xid, Vector, None, Vectors)\n",
    "            Y = bitsets.meta.bitset(yname, ymembers, yid, Vector, None, Vectors)\n",
    "        else:\n",
    "            X = bitsets.bitset(xname, xmembers, Vector, tuple=Vectors)\n",
    "            Y = bitsets.bitset(yname, ymembers, Vector, tuple=Vectors)\n",
    "\n",
    "        x = X.Tuple.frombools(xbools)\n",
    "        y = Y.Tuple.frombools(zip(*x.bools()))\n",
    "\n",
    "        self = super().__new__(cls, (x, y))\n",
    "\n",
    "        x._pair_with(self, 0, y)\n",
    "        y._pair_with(self, 1, x)\n",
    "\n",
    "        return self\n",
    "\n",
    "    __call__ = tuple.__getitem__\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'<{self.__class__.__name__}({self[0]!r}, {self[1]!r})>'\n",
    "\n",
    "    def __reduce__(self):\n",
    "        X, Y = (v.BitSet for v in self)\n",
    "        return (self.__class__,\n",
    "                (X.__name__, Y.__name__,\n",
    "                 X._members, Y._members,\n",
    "                 self[0].bools(),\n",
    "                 (X._id, Y._id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74666d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Concept():\n",
    "    \"\"\"Formal concept as pair of extent and intent.\n",
    "    Example:\n",
    "        >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "        >>> concept = lattice['+1',]\n",
    "        >>> concept\n",
    "        <Concept {1sg, 1pl} <-> [+1 -2 -3] <=> +1>\n",
    "        >>> concept.index, concept.dindex\n",
    "        (7, 6)\n",
    "        >>> concept.objects, concept.properties\n",
    "        ((), ('+1',))\n",
    "        >>> concept.atoms  # doctest: +NORMALIZE_WHITESPACE\n",
    "        (<Atom {1sg} <-> [+1 -2 -3 +sg -pl] <=> 1sg>,\n",
    "         <Atom {1pl} <-> [+1 -2 -3 +pl -sg] <=> 1pl>)\n",
    "        >>> concept.upper_neighbors  # doctest: +NORMALIZE_WHITESPACE\n",
    "        (<Concept {1sg, 1pl, 2sg, 2pl} <-> [-3] <=> -3>,\n",
    "         <Concept {1sg, 1pl, 3sg, 3pl} <-> [-2] <=> -2>)\n",
    "        >>> concept.lower_neighbors  # doctest: +NORMALIZE_WHITESPACE\n",
    "        (<Atom {1sg} <-> [+1 -2 -3 +sg -pl] <=> 1sg>,\n",
    "         <Atom {1pl} <-> [+1 -2 -3 +pl -sg] <=> 1pl>)\n",
    "    \"\"\"\n",
    "    objects = ()\n",
    "\n",
    "    properties = ()\n",
    "\n",
    "    def __init__(self, lattice, extent, intent, upper, lower) -> None:\n",
    "        self.lattice = lattice\n",
    "        self._extent = extent\n",
    "        self._intent = intent\n",
    "        self.upper_neighbors = upper\n",
    "        self.lower_neighbors = lower\n",
    " \n",
    "    def _eq(self, other):\n",
    "        if not isinstance(other, Concept):\n",
    "            return NotImplemented\n",
    "\n",
    "        if (other._extent.members() != self._extent.members()\n",
    "            or other._intent.members() != self._intent.members()):\n",
    "            return False\n",
    "\n",
    "        for attname in ('upper_neighbors', 'lower_neighbors'):\n",
    "            s_neighbors = getattr(self, attname)\n",
    "            o_neighbors = getattr(other, attname)\n",
    "            if len(o_neighbors) != len(s_neighbors):\n",
    "                return False\n",
    "            for s, o in zip(s_neighbors, o_neighbors):\n",
    "                if o._extent.members() != s._extent.members():\n",
    "                    return False\n",
    "        return True\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield ``extent`` and ``intent`` (e.g. for pair unpacking).\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> extent, intent = lattice['+1',]\n",
    "            >>> print(extent, intent)\n",
    "            ('1sg', '1pl') ('+1', '-2', '-3')\n",
    "        \"\"\"\n",
    "        yield self._extent.members()\n",
    "        yield self._intent.members()\n",
    "\n",
    "    @property\n",
    "    def extent(self) -> typing.Tuple[str, ...]:\n",
    "        \"\"\"The objects subsumed by the concept.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> lattice['+1',].extent\n",
    "            ('1sg', '1pl')\n",
    "        \"\"\"\n",
    "        return self._extent.members()\n",
    "\n",
    "    @property\n",
    "    def intent(self) -> typing.Tuple[str, ...]:\n",
    "        \"\"\"The properties implied by the concept.\"\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> lattice['+1',].intent\n",
    "            ('+1', '-2', '-3')\n",
    "        \"\"\"\n",
    "        return self._intent.members()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> print(lattice['+1',])\n",
    "            {1sg, 1pl} <-> [+1 -2 -3] <=> +1\n",
    "        \"\"\"\n",
    "        extent = ', '.join(self._extent.members())\n",
    "        intent = ' '.join(self._intent.members())\n",
    "        objects = ' <=> {}'.format(' '.join(self.objects)) if self.objects else ''\n",
    "        properties = ' <=> {}'.format(' '.join(self.properties)) if self.properties else ''\n",
    "        return f'{{{extent}}} <-> [{intent}]{objects}{properties}'\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> lattice['+1',]\n",
    "            <Concept {1sg, 1pl} <-> [+1 -2 -3] <=> +1>\n",
    "        \"\"\"\n",
    "        return f'<{self.__class__.__name__} {self}>'\n",
    "\n",
    "    def upset(self, _sortkey=operator.attrgetter('index'),\n",
    "              _next_concepts=operator.attrgetter('upper_neighbors')):\n",
    "        \"\"\"Yield implied concepts including ``self``.\n",
    "        Yields:\n",
    "            :class:`.Concept` instances.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> list(lattice['+1',].upset())  # doctest: +NORMALIZE_WHITESPACE\n",
    "            [<Concept {1sg, 1pl} <-> [+1 -2 -3] <=> +1>,\n",
    "             <Concept {1sg, 1pl, 2sg, 2pl} <-> [-3] <=> -3>,\n",
    "             <Concept {1sg, 1pl, 3sg, 3pl} <-> [-2] <=> -2>,\n",
    "             <Supremum {1sg, 1pl, 2sg, 2pl, 3sg, 3pl} <-> []>]\n",
    "        \"\"\"\n",
    "        heap = [(_sortkey(c), c) for c in [self]]\n",
    "        heapq.heapify(heap)\n",
    "\n",
    "        push = functools.partial(heapq.heappush, heap)\n",
    "        pop = functools.partial(heapq.heappop, heap)\n",
    "\n",
    "        seen = -1\n",
    "\n",
    "        while heap:\n",
    "            index, concept = pop()\n",
    "            if index > seen:\n",
    "                seen = index\n",
    "                yield concept\n",
    "                for c in _next_concepts(concept):\n",
    "                    push((_sortkey(c), c))\n",
    "\n",
    "    def downset(self,\n",
    "                _sortkey=operator.attrgetter('dindex'),\n",
    "                _next_concepts=operator.attrgetter('lower_neighbors')):\n",
    "        \"\"\"Yield subsumed concepts including ``self``.\n",
    "        Yields:\n",
    "            :class:`.Concept` instances.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> list(lattice['+1',].downset())  # doctest: +NORMALIZE_WHITESPACE\n",
    "            [<Concept {1sg, 1pl} <-> [+1 -2 -3] <=> +1>,\n",
    "             <Atom {1sg} <-> [+1 -2 -3 +sg -pl] <=> 1sg>,\n",
    "             <Atom {1pl} <-> [+1 -2 -3 +pl -sg] <=> 1pl>,\n",
    "             <Infimum {} <-> [+1 -1 +2 -2 +3 -3 +sg +pl -sg -pl]>]\n",
    "        \"\"\"\n",
    "        heap = [(_sortkey(c), c) for c in [self]]\n",
    "        heapq.heapify(heap)\n",
    "\n",
    "        push = functools.partial(heapq.heappush, heap)\n",
    "        pop = functools.partial(heapq.heappop, heap)\n",
    "\n",
    "        seen = -1\n",
    "\n",
    "        while heap:\n",
    "            index, concept = pop()\n",
    "            if index > seen:\n",
    "                seen = index\n",
    "                yield concept\n",
    "                for c in _next_concepts(concept):\n",
    "                    push((_sortkey(c), c))\n",
    "\n",
    "    def implies(self, other: 'Concept') -> bool:\n",
    "        \"\"\"Implication comparison.\n",
    "        Args:\n",
    "            other: :class:`.Concept` instance from the same lattice.\n",
    "        Returns:\n",
    "            bool: ``True`` if ``self`` implies ``other`` else ``False``.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> lattice['+1',] <= lattice['-3',] <= lattice['-3',] <= lattice[()]\n",
    "            True\n",
    "            >>> lattice['+1',] <= lattice['+sg',] or lattice['+sg',] <= lattice['+1',]\n",
    "            False\n",
    "        \"\"\"\n",
    "        return self._extent & other._extent == self._extent\n",
    "\n",
    "    __le__ = implies\n",
    "\n",
    "    def subsumes(self, other: 'Concept') -> bool:\n",
    "        \"\"\"Subsumption comparison.\n",
    "        Args:\n",
    "            other: :class:`.Concept` instance from the same lattice.\n",
    "        Returns:\n",
    "            bool: ``True`` if ``self`` subsumes ``other`` else ``False``.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> lattice['+1',] >= lattice['+1', '+sg'] >= lattice['+1', '+sg'] >= lattice['+1', '-1']\n",
    "            True\n",
    "            >>> lattice['+1',] >= lattice['+sg',] or lattice['+sg',] >= lattice['+1',]\n",
    "            False\n",
    "        \"\"\"\n",
    "        return self._extent | other._extent == self._extent\n",
    "\n",
    "    __ge__ = subsumes\n",
    "\n",
    "    def properly_implies(self, other: 'Concept') -> bool:\n",
    "        \"\"\"Proper implication comparison.\n",
    "        Args:\n",
    "            other: :class:`.Concept` instance from the same lattice.\n",
    "        Returns:\n",
    "            bool: ``True`` if ``self`` properly implies ``other`` else ``False``.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> lattice['+1',] < lattice['-3',] < lattice[()]\n",
    "            True\n",
    "        \"\"\"\n",
    "        return self._extent & other._extent == self._extent != other._extent\n",
    "\n",
    "    __lt__ = properly_implies\n",
    "\n",
    "    def properly_subsumes(self, other: 'Concept') -> bool:\n",
    "        \"\"\"Proper subsumption comparison.\n",
    "        Args:\n",
    "            other: :class:`.Concept` instance from the same lattice.\n",
    "        Returns:\n",
    "            bool: ``True`` if ``self`` properly subsumes ``other`` else ``False``.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> lattice['+1',] > lattice['+1', '+sg'] > lattice['+1', '-1']\n",
    "            True\n",
    "        \"\"\"\n",
    "        return self._extent | other._extent == self._extent != other._extent\n",
    "\n",
    "    __gt__ = properly_subsumes\n",
    "\n",
    "    def join(self, other: 'Concept') -> 'Concept':\n",
    "        \"\"\"Least upper bound, supremum, or, generalization.\n",
    "        Args:\n",
    "            other: :class:`.Concept` instance from the same lattice.\n",
    "        Returns:\n",
    "            :class:`.Concept` instance from the same lattice.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> lattice['+1',].join(lattice['+2',])\n",
    "            <Concept {1sg, 1pl, 2sg, 2pl} <-> [-3] <=> -3>\n",
    "            >>> lattice['+2',] | lattice['+1',]\n",
    "            <Concept {1sg, 1pl, 2sg, 2pl} <-> [-3] <=> -3>\n",
    "        \"\"\"\n",
    "        common = self._extent | other._extent\n",
    "        extent = self.lattice._context._extents.double(common)\n",
    "        return self.lattice._mapping[extent]\n",
    "\n",
    "    __or__ = join\n",
    "\n",
    "    def meet(self, other: 'Concept') -> 'Concept':\n",
    "        \"\"\"Greatest lower bound, infimum, and, unification.\n",
    "        Args:\n",
    "            other: :class:`.Concept` instance from the same lattice.\n",
    "        Returns:\n",
    "            :class:`.Concept` instance from the same lattice.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> lattice['-1', '-2'].meet(lattice['-pl',])\n",
    "            <Atom {3sg} <-> [-1 -2 +3 +sg -pl] <=> 3sg>\n",
    "            >>> lattice['-pl',] & lattice['-1', '-2']\n",
    "            <Atom {3sg} <-> [-1 -2 +3 +sg -pl] <=> 3sg>\n",
    "        \"\"\"\n",
    "        common = self._extent & other._extent\n",
    "        extent = self.lattice._context._extents.double(common)\n",
    "        return self.lattice._mapping[extent]\n",
    "\n",
    "    __and__ = meet\n",
    "\n",
    "    def incompatible_with(self, other: 'Concept') -> bool:\n",
    "        \"\"\"Infimum meet comparison.\n",
    "        Args:\n",
    "            other: :class:`.Concept` instance from the same lattice.\n",
    "        Returns:\n",
    "            bool: ``True`` if ``self`` is incompatible with ``other`` else ``False``.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> lattice['+1',].incompatible_with(lattice['+3',])\n",
    "            True\n",
    "            >>> lattice['+1',].incompatible_with(lattice['+sg',])\n",
    "            False\n",
    "        \"\"\"\n",
    "        return not self._extent & other._extent\n",
    "\n",
    "    def complement_of(self, other: 'Concept') -> bool:\n",
    "        \"\"\"Infimum meet and supremum join comparison.\n",
    "        Args:\n",
    "            other: :class:`.Concept` instance from the same lattice.\n",
    "        Returns:\n",
    "            bool: ``True`` if ``self`` is the complement of ``other`` else ``False``.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> lattice['+1',].complement_of(lattice['-1',])\n",
    "            True\n",
    "            >>> lattice['+1',].complement_of(lattice['+3',])\n",
    "            False\n",
    "        \"\"\"\n",
    "        return (not self._extent & other._extent \n",
    "                and (self._extent | other._extent) == self.lattice.supremum._extent)\n",
    "\n",
    "    def subcontrary_with(self, other: 'Concept') -> bool:\n",
    "        \"\"\"Non-infimum meet and supremum join comparison.\n",
    "        Args:\n",
    "            other: :class:`.Concept` instance from the same lattice.\n",
    "        Returns:\n",
    "            bool: ``True`` if ``self`` is the subcontrary to ``other`` else ``False``.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> lattice['-1',].subcontrary_with(lattice['-3',])\n",
    "            True\n",
    "            >>> lattice['-1',].subcontrary_with(lattice['+sg',])\n",
    "            False\n",
    "        \"\"\"\n",
    "        return (self._extent & other._extent\n",
    "                and (self._extent | other._extent) == self.lattice.supremum._extent)\n",
    "\n",
    "    def orthogonal_to(self, other: 'Concept') -> bool:\n",
    "        \"\"\"Non-infimum meet, incomparable, and non-supremum join comparison.\n",
    "        Args:\n",
    "            other: :class:`.Concept` instance from the same lattice.\n",
    "        Returns:\n",
    "            bool: ``True`` if ``self`` is orthogonal to ``other`` else ``False``.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> lattice['+1',].orthogonal_to(lattice['+sg',])\n",
    "            True\n",
    "            >>> lattice['+1',].orthogonal_to(lattice['+3',])\n",
    "            False\n",
    "        \"\"\"\n",
    "        meet = self._extent & other._extent\n",
    "        return (not not meet and meet != self._extent and meet != other._extent\n",
    "                and (self._extent | other._extent) != self.lattice.supremum._extent)\n",
    "\n",
    "    def minimal(self) -> typing.Tuple[str, ...]:\n",
    "        \"\"\"Shortlex minimal properties generating the concept.\n",
    "        Returns:\n",
    "            Property name strings.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> lattice['+1',].minimal()\n",
    "            ('+1',)\n",
    "        Note:\n",
    "            For :class:`.Infimum`, this returns **all** properties instead of\n",
    "            the first contradictory subset of properties.\n",
    "        \"\"\"\n",
    "        return self.lattice._context._minimal(self._extent, self._intent).members()\n",
    "\n",
    "    def attributes(self) -> typing.Iterator[typing.Tuple[str]]:\n",
    "        \"\"\"Yield properties generating the concept in shortlex order.\n",
    "        Yields:\n",
    "            Tuples of property name strings.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> list(lattice['+1',].attributes())\n",
    "            [('+1',), ('+1', '-2'), ('+1', '-3'), ('-2', '-3'), ('+1', '-2', '-3')]\n",
    "        \"\"\"\n",
    "        minimize = self.lattice._context._minimize(self._extent, self._intent)\n",
    "        return (i.members() for i in minimize)\n",
    "\n",
    "\n",
    "class Infimum(Concept):\n",
    "    \"\"\"Contradiction with empty ``extent`` and universal ``intent``.\n",
    "    Example:\n",
    "        >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "        >>> lattice.infimum\n",
    "        <Infimum {} <-> [+1 -1 +2 -2 +3 -3 +sg +pl -sg -pl]>\n",
    "        >>> lattice.infimum.index, lattice.infimum.dindex\n",
    "        (0, 21)\n",
    "        >>> lattice.infimum.objects, lattice.infimum.properties\n",
    "        ((), ())\n",
    "        >>> lattice.infimum.atoms\n",
    "        ()\n",
    "        >>> lattice.infimum.upper_neighbors  # doctest: +NORMALIZE_WHITESPACE\n",
    "        (<Atom {1sg} <-> [+1 -2 -3 +sg -pl] <=> 1sg>,\n",
    "         <Atom {1pl} <-> [+1 -2 -3 +pl -sg] <=> 1pl>,\n",
    "         <Atom {2sg} <-> [-1 +2 -3 +sg -pl] <=> 2sg>,\n",
    "         <Atom {2pl} <-> [-1 +2 -3 +pl -sg] <=> 2pl>,\n",
    "         <Atom {3sg} <-> [-1 -2 +3 +sg -pl] <=> 3sg>,\n",
    "         <Atom {3pl} <-> [-1 -2 +3 +pl -sg] <=> 3pl>)\n",
    "        >>> lattice.infimum.lower_neighbors\n",
    "        ()\n",
    "    \"\"\"\n",
    "\n",
    "    def minimal(self) -> typing.Tuple[str, ...]:\n",
    "        \"\"\"Shortlex minimal properties generating the concept.\n",
    "        Returns:\n",
    "            Property name strings.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> lattice.infimum.minimal()\n",
    "            ('+1', '-1', '+2', '-2', '+3', '-3', '+sg', '+pl', '-sg', '-pl')\n",
    "        Note:\n",
    "            For :class:`.Infimum`, this returns **all** properties instead of\n",
    "            the first contradictory subset of properties.\n",
    "        \"\"\"\n",
    "        return self._intent.members()\n",
    "\n",
    "\n",
    "class Atom(Concept):\n",
    "    \"\"\"Concept which is a minimal non-zero element in its lattice.\n",
    "    Example:\n",
    "        >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "        >>> lattice.atoms  # doctest: +NORMALIZE_WHITESPACE\n",
    "        (<Atom {1sg} <-> [+1 -2 -3 +sg -pl] <=> 1sg>,\n",
    "         <Atom {1pl} <-> [+1 -2 -3 +pl -sg] <=> 1pl>,\n",
    "         <Atom {2sg} <-> [-1 +2 -3 +sg -pl] <=> 2sg>,\n",
    "         <Atom {2pl} <-> [-1 +2 -3 +pl -sg] <=> 2pl>,\n",
    "         <Atom {3sg} <-> [-1 -2 +3 +sg -pl] <=> 3sg>,\n",
    "         <Atom {3pl} <-> [-1 -2 +3 +pl -sg] <=> 3pl>)\n",
    "        >>> lattice.atoms[0].index, lattice.atoms[0].dindex\n",
    "        (1, 15)\n",
    "        >>> lattice.atoms[0].objects, lattice.atoms[0].properties\n",
    "        (('1sg',), ())\n",
    "        >>> lattice.atoms[0].atoms\n",
    "        (<Atom {1sg} <-> [+1 -2 -3 +sg -pl] <=> 1sg>,)\n",
    "        >>> lattice.atoms[0].upper_neighbors  # doctest: +NORMALIZE_WHITESPACE\n",
    "        (<Concept {1sg, 1pl} <-> [+1 -2 -3] <=> +1>,\n",
    "         <Concept {1sg, 2sg} <-> [-3 +sg -pl]>,\n",
    "         <Concept {1sg, 3sg} <-> [-2 +sg -pl]>)\n",
    "        >>> lattice.atoms[0].lower_neighbors  # doctest: +NORMALIZE_WHITESPACE\n",
    "        (<Infimum {} <-> [+1 -1 +2 -2 +3 -3 +sg +pl -sg -pl]>,)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "class Supremum(Concept):\n",
    "    \"\"\"Tautology with universal ``extent`` and empty ``intent``.\n",
    "    Example:\n",
    "        >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "        >>> lattice.supremum\n",
    "        <Supremum {1sg, 1pl, 2sg, 2pl, 3sg, 3pl} <-> []>\n",
    "        >>> lattice.supremum.index, lattice.supremum.dindex\n",
    "        (21, 0)\n",
    "        >>> lattice.supremum.objects, lattice.supremum.properties\n",
    "        ((), ())\n",
    "        >>> lattice.supremum.atoms  # doctest: +NORMALIZE_WHITESPACE\n",
    "        (<Atom {1sg} <-> [+1 -2 -3 +sg -pl] <=> 1sg>,\n",
    "         <Atom {1pl} <-> [+1 -2 -3 +pl -sg] <=> 1pl>,\n",
    "         <Atom {2sg} <-> [-1 +2 -3 +sg -pl] <=> 2sg>,\n",
    "         <Atom {2pl} <-> [-1 +2 -3 +pl -sg] <=> 2pl>,\n",
    "         <Atom {3sg} <-> [-1 -2 +3 +sg -pl] <=> 3sg>,\n",
    "         <Atom {3pl} <-> [-1 -2 +3 +pl -sg] <=> 3pl>)\n",
    "        >>> lattice.supremum.upper_neighbors\n",
    "        ()\n",
    "        >>> lattice.supremum.lower_neighbors  # doctest: +NORMALIZE_WHITESPACE\n",
    "        (<Concept {1sg, 1pl, 2sg, 2pl} <-> [-3] <=> -3>,\n",
    "         <Concept {1sg, 1pl, 3sg, 3pl} <-> [-2] <=> -2>,\n",
    "         <Concept {2sg, 2pl, 3sg, 3pl} <-> [-1] <=> -1>,\n",
    "         <Concept {1sg, 2sg, 3sg} <-> [+sg -pl] <=> +sg -pl>,\n",
    "         <Concept {1pl, 2pl, 3pl} <-> [+pl -sg] <=> +pl -sg>)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36f54d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lattice():\n",
    "    \"\"\"Formal concept lattice as directed acyclic graph of concepts.\n",
    "    Example:\n",
    "        >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "        >>> lattice\n",
    "        <Lattice object of 6 atoms 22 concepts 5 coatoms at 0x...>\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def _longlex(concept):\n",
    "        return concept._extent.longlex()\n",
    "\n",
    "    @staticmethod\n",
    "    def _shortlex(concept):\n",
    "        return concept._extent.shortlex()\n",
    "\n",
    "    @classmethod\n",
    "    def _fromlist(cls, context, lattice, unordered) -> 'Lattice':\n",
    "        make_objects = context._Objects.fromint\n",
    "        make_properties = context._Properties.fromint\n",
    "        inst = object.__new__(cls)\n",
    "        concepts = [Concept(inst,\n",
    "                            make_objects(sum(1 << e for e in ex)),\n",
    "                            make_properties(sum(1 << i for i in in_)),\n",
    "                            up, lo)\n",
    "                    for ex, in_, up, lo in lattice]\n",
    "\n",
    "        if unordered:\n",
    "            index_map = dict(enumerate(concepts))\n",
    "            shortlex = inst._shortlex\n",
    "            longlex = inst._longlex\n",
    "            concepts.sort(key=shortlex)\n",
    "            for index, c in enumerate(concepts):\n",
    "                c.index = index\n",
    "                upper = (index_map[i] for i in c.upper_neighbors)\n",
    "                lower = (index_map[i] for i in c.lower_neighbors)\n",
    "                c.upper_neighbors = tuple(sorted(upper, key=shortlex))\n",
    "                c.lower_neighbors = tuple(sorted(lower, key=longlex))\n",
    "        else:\n",
    "            for index, c in enumerate(concepts):\n",
    "                c.index = index\n",
    "                c.upper_neighbors = tuple(concepts[i] for i in c.upper_neighbors)\n",
    "                c.lower_neighbors = tuple(concepts[i] for i in c.lower_neighbors)\n",
    "\n",
    "        cls._init(inst, context, concepts)\n",
    "        return inst\n",
    "\n",
    "    def __init__(self, context: 'Context', infimum=()) -> None:\n",
    "        \"\"\"Create lattice from context.\"\"\"\n",
    "        concepts = [Concept(self, *args)\n",
    "                    for args in context._lattice(infimum)]\n",
    "        mapping = self._make_mapping(concepts)\n",
    "\n",
    "        shortlex = self._shortlex\n",
    "        longlex = self._longlex\n",
    "        for index, c in enumerate(concepts):\n",
    "            c.index = index\n",
    "            upper = (mapping[u] for u in c.upper_neighbors)\n",
    "            lower = (mapping[l] for l in c.lower_neighbors)\n",
    "            c.upper_neighbors = tuple(sorted(upper, key=shortlex))\n",
    "            c.lower_neighbors = tuple(sorted(lower, key=longlex))\n",
    "\n",
    "        self._init(self, context, concepts, mapping=mapping)\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_mapping(concepts):\n",
    "        return {c._extent: c for c in concepts}\n",
    "\n",
    "    @staticmethod\n",
    "    def _init(inst,\n",
    "              context: 'Context',\n",
    "              concepts,\n",
    "              mapping=None, unpickle=False) -> None:\n",
    "        inst._context = context\n",
    "        inst._concepts = concepts\n",
    "\n",
    "        if mapping is None:\n",
    "            mapping = inst._make_mapping(inst._concepts)\n",
    "        inst._mapping = mapping\n",
    "\n",
    "        if unpickle:\n",
    "            return\n",
    "\n",
    "        atoms = inst.atoms\n",
    "        for dindex, c in enumerate(sorted(inst._concepts, key=inst._longlex)):\n",
    "            c.dindex = dindex\n",
    "            e = c._extent\n",
    "            c.atoms = tuple(a for a in atoms if e | a._extent == e)\n",
    "\n",
    "        inst._annotate(inst._context, inst._mapping)\n",
    "\n",
    "        for a in inst.atoms:\n",
    "            a.__class__ = Atom\n",
    "        inst.supremum.__class__ = Supremum\n",
    "        inst.infimum.__class__ = Infimum\n",
    "\n",
    "    @staticmethod\n",
    "    def _annotate(context, mapping):\n",
    "        \"\"\"Annotate object/attribute concepts with their objects/properties.\"\"\"\n",
    "        touched = set()\n",
    "        for o in context.objects:\n",
    "            extent = context.extension(context.intension([o]), raw=True)\n",
    "            c = mapping[extent]\n",
    "            if c.objects:\n",
    "                c.objects.append(o)\n",
    "            else:\n",
    "                c.objects = [o]\n",
    "                touched.add(c)\n",
    "\n",
    "        for c in touched:\n",
    "            c.objects = tuple(c.objects)\n",
    "\n",
    "        touched = set()\n",
    "        for p in context.properties:\n",
    "            extent = context.extension([p], raw=True)\n",
    "            c = mapping[extent]\n",
    "            if c.properties:\n",
    "                c.properties.append(p)\n",
    "            else:\n",
    "                c.properties = [p]\n",
    "                touched.add(c)\n",
    "\n",
    "        for c in touched:\n",
    "            c.properties = tuple(c.properties)\n",
    "\n",
    "    def __getstate__(self):\n",
    "        \"\"\"Pickle lattice as ``(context, concepts)`` tuple.\"\"\"\n",
    "        return self._context, self._concepts\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        \"\"\"Unpickle lattice from ``(context, concepts)`` tuple.\"\"\"\n",
    "        context, concepts = state\n",
    "        self._init(self, context, concepts, unpickle=True)\n",
    "\n",
    "    def _tolist(self):\n",
    "        return [(tuple(c._extent.iter_set()),\n",
    "                 tuple(c._intent.iter_set()),\n",
    "                 tuple(u.index for u in c.upper_neighbors),\n",
    "                 tuple(l.index for l in c.lower_neighbors))\n",
    "                for c in self._concepts]\n",
    "\n",
    "    def _eq(self, other) -> typing.Union[type(NotImplemented), bool]:\n",
    "        \"\"\"Return ``True`` if two lattices are equivalent.\n",
    "        Note:\n",
    "            Does not compares their context objects.\n",
    "            Lattice-equivalence comparison is present mainly for unit-tests\n",
    "            (not meant to be efficient). Context-comparison should be superior\n",
    "            in most cases.\n",
    "        \"\"\"\n",
    "        if not isinstance(other, Lattice):\n",
    "            return NotImplemented\n",
    "\n",
    "        if (len(other._concepts) != len(self._concepts)\n",
    "            or not all(s._eq(o) for s, o in zip(self._concepts, other._concepts))):\n",
    "            return False\n",
    "\n",
    "        if (len(other._mapping) != len(self._mapping)\n",
    "            or {e.members() for e in other._mapping}\n",
    "            != {e.members() for e in self._mapping}):\n",
    "            return False\n",
    "\n",
    "        for s, o in zip(self._concepts, other._concepts):\n",
    "            if (o.index != s.index or o.dindex != s.dindex\n",
    "                or [a._extent.members() for a in o.atoms]\n",
    "                != [a._extent.members() for a in s.atoms]\n",
    "                or o.objects != s.objects or o.properties != s.properties):\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"Return the full string representation of the lattice.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> print(lattice)  # doctest: +ELLIPSIS\n",
    "            <Lattice object of 6 atoms 22 concepts 5 coatoms at 0x...>\n",
    "                {} <-> [+1 -1 +2 -2 +3 -3 +sg +pl -sg -pl]\n",
    "                {1sg} <-> [+1 -2 -3 +sg -pl] <=> 1sg\n",
    "                {1pl} <-> [+1 -2 -3 +pl -sg] <=> 1pl\n",
    "                {2sg} <-> [-1 +2 -3 +sg -pl] <=> 2sg\n",
    "                {2pl} <-> [-1 +2 -3 +pl -sg] <=> 2pl\n",
    "                {3sg} <-> [-1 -2 +3 +sg -pl] <=> 3sg\n",
    "                {3pl} <-> [-1 -2 +3 +pl -sg] <=> 3pl\n",
    "                {1sg, 1pl} <-> [+1 -2 -3] <=> +1\n",
    "                {1sg, 2sg} <-> [-3 +sg -pl]\n",
    "                {1sg, 3sg} <-> [-2 +sg -pl]\n",
    "                {1pl, 2pl} <-> [-3 +pl -sg]\n",
    "                {1pl, 3pl} <-> [-2 +pl -sg]\n",
    "                {2sg, 2pl} <-> [-1 +2 -3] <=> +2\n",
    "                {2sg, 3sg} <-> [-1 +sg -pl]\n",
    "                {2pl, 3pl} <-> [-1 +pl -sg]\n",
    "                {3sg, 3pl} <-> [-1 -2 +3] <=> +3\n",
    "                {1sg, 2sg, 3sg} <-> [+sg -pl] <=> +sg -pl\n",
    "                {1pl, 2pl, 3pl} <-> [+pl -sg] <=> +pl -sg\n",
    "                {1sg, 1pl, 2sg, 2pl} <-> [-3] <=> -3\n",
    "                {1sg, 1pl, 3sg, 3pl} <-> [-2] <=> -2\n",
    "                {2sg, 2pl, 3sg, 3pl} <-> [-1] <=> -1\n",
    "                {1sg, 1pl, 2sg, 2pl, 3sg, 3pl} <-> []\n",
    "        \"\"\"\n",
    "        concepts = '\\n'.join(f'    {c}' for c in self._concepts)\n",
    "        return f'{self!r}\\n{concepts}'\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"Return the debug string representation of the lattice.\n",
    "        Example:\n",
    "            >>> lattice = \n",
    "            Context.fromstring('''\n",
    "            ...    |+1|-1|+2|-2|+3|-3|+sg|+du|+pl|-sg|-du|-pl|\n",
    "            ... 1s | X|  |  | X|  | X|  X|   |   |   |  X|  X|\n",
    "            ... 1de| X|  |  | X|  | X|   |  X|   |  X|   |  X|\n",
    "            ... 1pe| X|  |  | X|  | X|   |   |  X|  X|  X|   |\n",
    "            ... 1di| X|  | X|  |  | X|   |  X|   |  X|   |  X|\n",
    "            ... 1pi| X|  | X|  |  | X|   |   |  X|  X|  X|   |\n",
    "            ... 2s |  | X| X|  |  | X|  X|   |   |   |  X|  X|\n",
    "            ... 2d |  | X| X|  |  | X|   |  X|   |  X|   |  X|\n",
    "            ... 2p |  | X| X|  |  | X|   |   |  X|  X|  X|   |\n",
    "            ... 3s |  | X|  | X| X|  |  X|   |   |   |  X|  X|\n",
    "            ... 3d |  | X|  | X| X|  |   |  X|   |  X|   |  X|\n",
    "            ... 3p |  | X|  | X| X|  |   |   |  X|  X|  X|   |\n",
    "            ... ''').lattice\n",
    "            >>> lattice  # doctest: +ELLIPSIS\n",
    "            <Lattice object of 11 atoms 65 concepts 6 coatoms at 0x...>\n",
    "        \"\"\"\n",
    "        return (f'<{self.__class__.__name__} object'\n",
    "                f' of {len(self.atoms)} atoms'\n",
    "                f' {len(self)} concepts'\n",
    "                f' {len(self.supremum.lower_neighbors)} coatoms'\n",
    "                f' at {id(self):#x}>')\n",
    "\n",
    "    def __call__(self, properties: typing.Tuple[str]) -> Concept:\n",
    "        \"\"\"Return concept having all given ``properties`` as intension.\n",
    "        Args:\n",
    "            properties: Tuple of property names.\n",
    "        Returns:\n",
    "            :class:`.Concept` instance from this lattice.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> lattice(['+1', '-sg'])\n",
    "            <Atom {1pl} <-> [+1 -2 -3 +pl -sg] <=> 1pl>\n",
    "        \"\"\"\n",
    "        extent = self._context.extension(properties, raw=True)\n",
    "        return self._mapping[extent]\n",
    "\n",
    "    def __getitem__(self, key: typing.Union[int, typing.Tuple[str, ...]]) -> Concept:\n",
    "        \"\"\"Return concept by index, intension, or extension.\n",
    "        Args:\n",
    "            key: Integer index, properties tuple, or objects tuple.\n",
    "        Returns:\n",
    "            :class:`.Concept` instance from this lattice.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> lattice[1:3]  # doctest: +NORMALIZE_WHITESPACE\n",
    "            [<Atom {1sg} <-> [+1 -2 -3 +sg -pl] <=> 1sg>,\n",
    "             <Atom {1pl} <-> [+1 -2 -3 +pl -sg] <=> 1pl>]\n",
    "            >>> lattice['-1', '-sg']\n",
    "            <Concept {2pl, 3pl} <-> [-1 +pl -sg]>\n",
    "            >>> lattice['1sg', '1pl', '2pl']\n",
    "            <Concept {1sg, 1pl, 2sg, 2pl} <-> [-3] <=> -3>\n",
    "        \"\"\"\n",
    "        if isinstance(key, (int, slice)):\n",
    "            return self._concepts[key]\n",
    "\n",
    "        if not key:\n",
    "            return self.supremum\n",
    "\n",
    "        extent, intent = self._context.__getitem__(key, raw=True)\n",
    "        return self._mapping[extent]\n",
    "\n",
    "    def __iter__(self) -> typing.Iterator[Concept]:\n",
    "        \"\"\"Yield all concepts of the lattice.\n",
    "        Yields:\n",
    "            All :class:`.Concept` instances from this lattice.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> iterconcepts = iter(lattice)\n",
    "            >>> next(iterconcepts)\n",
    "            <Infimum {} <-> [+1 -1 +2 -2 +3 -3 +sg +pl -sg -pl]>\n",
    "            >>> next(iterconcepts)\n",
    "            <Atom {1sg} <-> [+1 -2 -3 +sg -pl] <=> 1sg>\n",
    "        \"\"\"\n",
    "        return iter(self._concepts)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Return the number of concepts in the lattice.\n",
    "        Returns:\n",
    "            Number of lattice concepts.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> len(lattice)\n",
    "            22\n",
    "        \"\"\"\n",
    "        return len(self._concepts)\n",
    "\n",
    "    def join(self, concepts: typing.Iterable[Concept]) -> Concept:\n",
    "        \"\"\"Return the nearest concept that subsumes all given concepts.\n",
    "        Args:\n",
    "            concepts: :class:`.Concept` instances from this lattice.\n",
    "        Returns:\n",
    "            :class:`.Concept` instance from this lattice.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> lattice.join([])\n",
    "            <Infimum {} <-> [+1 -1 +2 -2 +3 -3 +sg +pl -sg -pl]>\n",
    "            >>> lattice.join([lattice['1sg',], lattice['1pl',], lattice['2sg',]])\n",
    "            <Concept {1sg, 1pl, 2sg, 2pl} <-> [-3] <=> -3>\n",
    "        \"\"\"\n",
    "        extents = (c._extent for c in concepts)\n",
    "        join = self._context._Objects.reduce_or(extents)\n",
    "        return self._mapping[join.double()]\n",
    "\n",
    "    def meet(self, concepts: typing.Iterable[Concept]) -> Concept:\n",
    "        \"\"\"Return the nearest concept that implies all given concepts.\n",
    "        Args:\n",
    "            concepts: :class:`.Concept` instances from this lattice.\n",
    "        Returns:\n",
    "            :class:`.Concept` instance from this lattice.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> lattice.meet([])\n",
    "            <Supremum {1sg, 1pl, 2sg, 2pl, 3sg, 3pl} <-> []>\n",
    "            >>> lattice.meet([lattice['-1',], lattice['-2',], lattice['-pl',]])\n",
    "            <Atom {3sg} <-> [-1 -2 +3 +sg -pl] <=> 3sg>\n",
    "        \"\"\"\n",
    "        extents = (c._extent for c in concepts)\n",
    "        meet = self._context._Objects.reduce_and(extents)\n",
    "        return self._mapping[meet.double()]\n",
    "\n",
    "    def upset_union(self, concepts: typing.Iterable[Concept], _sortkey=operator.attrgetter('index'),\n",
    "                    _next_concepts=operator.attrgetter('upper_neighbors')) -> typing.Iterator[Concept]:\n",
    "        \"\"\"Yield all concepts that subsume any of the given ones.\n",
    "        Args:\n",
    "            concepts: :class:`.Concept` instances from this lattice.\n",
    "        Yields:\n",
    "            :class:`.Concept` instances from this lattice.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> list(lattice.upset_union([lattice['+1',], lattice['+2',]]))  # doctest: +NORMALIZE_WHITESPACE\n",
    "            [<Concept {1sg, 1pl} <-> [+1 -2 -3] <=> +1>,\n",
    "             <Concept {2sg, 2pl} <-> [-1 +2 -3] <=> +2>,\n",
    "             <Concept {1sg, 1pl, 2sg, 2pl} <-> [-3] <=> -3>,\n",
    "             <Concept {1sg, 1pl, 3sg, 3pl} <-> [-2] <=> -2>,\n",
    "             <Concept {2sg, 2pl, 3sg, 3pl} <-> [-1] <=> -1>,\n",
    "             <Supremum {1sg, 1pl, 2sg, 2pl, 3sg, 3pl} <-> []>]\n",
    "        \"\"\"\n",
    "        concepts = set(concepts)\n",
    "        if len(concepts) < 2:\n",
    "            return iter(concepts)\n",
    "        concepts = (item for item, pairs in groupby(permutations(concepts, 2), key=operator.itemgetter(0))\n",
    "                if not any(starmap(Concept.properly_subsumes, pairs)))\n",
    "\n",
    "        heap = [(_sortkey(c), c) for c in concepts]\n",
    "        heapq.heapify(heap)\n",
    "\n",
    "        push = functools.partial(heapq.heappush, heap)\n",
    "        pop = functools.partial(heapq.heappop, heap)\n",
    "\n",
    "        seen = -1\n",
    "\n",
    "        while heap:\n",
    "            index, concept = pop()\n",
    "            if index > seen:\n",
    "                seen = index\n",
    "                yield concept\n",
    "                for c in _next_concepts(concept):\n",
    "                    push((_sortkey(c), c))\n",
    "    \n",
    "    \n",
    "    def downset_union(self, concepts: typing.Iterable[Concept],\n",
    "                    _sortkey=operator.attrgetter('dindex'),\n",
    "                    _next_concepts=operator.attrgetter('lower_neighbors')) -> typing.Iterator[Concept]:\n",
    "        \"\"\"Yield all concepts that imply any of the given ones.\n",
    "        Args:\n",
    "            concepts: :class:`.Concept` instances from this lattice.\n",
    "        Yields:\n",
    "            :class:`.Concept` instances from this lattice.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> list(lattice.downset_union([lattice['+1',], lattice['+2',]]))  # doctest: +NORMALIZE_WHITESPACE\n",
    "            [<Concept {1sg, 1pl} <-> [+1 -2 -3] <=> +1>,\n",
    "             <Concept {2sg, 2pl} <-> [-1 +2 -3] <=> +2>,\n",
    "             <Atom {1sg} <-> [+1 -2 -3 +sg -pl] <=> 1sg>,\n",
    "             <Atom {1pl} <-> [+1 -2 -3 +pl -sg] <=> 1pl>,\n",
    "             <Atom {2sg} <-> [-1 +2 -3 +sg -pl] <=> 2sg>,\n",
    "             <Atom {2pl} <-> [-1 +2 -3 +pl -sg] <=> 2pl>,\n",
    "             <Infimum {} <-> [+1 -1 +2 -2 +3 -3 +sg +pl -sg -pl]>]\n",
    "        \"\"\"\n",
    "        concepts = set(concepts)\n",
    "        if len(concepts) < 2:\n",
    "            return iter(concepts)\n",
    "        concepts = (item for item, pairs in groupby(permutations(concepts, 2), key=operator.itemgetter(0))\n",
    "                if not any(starmap(Concept.properly_implies, pairs)))\n",
    "\n",
    "        heap = [(_sortkey(c), c) for c in concepts]\n",
    "        heapq.heapify(heap)\n",
    "\n",
    "        push = functools.partial(heapq.heappush, heap)\n",
    "        pop = functools.partial(heapq.heappop, heap)\n",
    "\n",
    "        seen = -1\n",
    "\n",
    "        while heap:\n",
    "            index, concept = pop()\n",
    "            if index > seen:\n",
    "                seen = index\n",
    "                yield concept\n",
    "                for c in _next_concepts(concept):\n",
    "                    push((_sortkey(c), c))\n",
    "\n",
    "    def upset_generalization(self, concepts: typing.Iterable[Concept]) -> typing.Iterator[Concept]:\n",
    "        \"\"\"Yield all concepts that subsume only the given ones.\n",
    "        Args:\n",
    "            concepts: :class:`.Concept` instances from this lattice.\n",
    "        Yields:\n",
    "            :class:`.Concept` instances from this lattice.\n",
    "        Note:\n",
    "            This method is EXPERIMENTAL and might change without notice.\n",
    "        \"\"\"\n",
    "        maximal_concepts = set(concepts)\n",
    "        if len(maximal_concepts) < 2:\n",
    "            return iter(maximal_concepts)\n",
    "        maximal_concepts = (item for item, pairs in groupby(permutations(maximal_concepts, 2), key=operator.itemgetter(0))\n",
    "                if not any(starmap(Concept.properly_subsumes, pairs)))\n",
    "        \n",
    "        heap = [(c.index, c) for c in maximal_concepts]\n",
    "        heapq.heapify(heap)\n",
    "        push, pop = heapq.heappush, heapq.heappop\n",
    "        extents = (c._extent for i, c in heap)\n",
    "        target = self._context._Objects.reduce_or(extents)\n",
    "        seen = -1\n",
    "        while heap:\n",
    "            index, concept = pop(heap)\n",
    "            if index > seen:\n",
    "                seen = index\n",
    "                if concept._extent | target == target:\n",
    "                    yield concept\n",
    "                    if concept._extent == target:\n",
    "                        return\n",
    "                    for c in concept.upper_neighbors:\n",
    "                        push(heap, (c.index, c))\n",
    "\n",
    "    def graphviz(self, filename=None, directory=None, render: bool = False, view: bool = False,\n",
    "                 make_object_label=' '.join, make_property_label=' '.join, **kwargs) -> graphviz.Digraph:\n",
    "        \"\"\"Return DOT source for visualizing the lattice graph.\n",
    "        Args:\n",
    "            filename: Path to the DOT source file for the Digraph.\n",
    "            directory: (Sub)directory for DOT source saving and rendering.\n",
    "            render: Call ``.render()`` on the result.\n",
    "            view: Call ``.render(view=True)`` on the result.\n",
    "            make_object_label: Callable with iterable of objects argument\n",
    "                               returning a string to be used as object label.\n",
    "            make_property_label: Callable with iterable of properties argument\n",
    "                                 returning a string to be used as object label.\n",
    "        Returns:\n",
    "            A ``graphviz.Digraph`` instance.\n",
    "        \"\"\"\n",
    "        dot = graphviz.Digraph(name=self.__class__.__name__,\n",
    "                               comment=repr(self),\n",
    "                               filename=filename, directory=directory,\n",
    "                               node_attr={'shape': 'circle', 'width': '.25', 'style': 'filled', 'label': ''},\n",
    "                               edge_attr={'dir': 'none', 'labeldistance': '1.5', 'minlen': '2'},\n",
    "                               **kwargs)\n",
    "\n",
    "        sortkey = [lambda c: c.index][0]\n",
    "        node_name = [lambda c: f'c{c.index:d}'][0]\n",
    "\n",
    "        for concept in self._concepts:\n",
    "            name = node_name(concept)\n",
    "            dot.node(name)\n",
    "\n",
    "            if concept.objects:\n",
    "                dot.edge(name, name,\n",
    "                         headlabel=make_object_label(concept.objects),\n",
    "                         labelangle='270', color='transparent')\n",
    "\n",
    "            if concept.attributes:\n",
    "                dot.edge(name, name,\n",
    "                         taillabel=make_property_label(concept.properties),\n",
    "                         labelangle='90', color='transparent')\n",
    "\n",
    "            dot.edges((name, node_name(c))\n",
    "                      for c in sorted(concept.lower_neighbors, key=sortkey))\n",
    "\n",
    "        if render or view:\n",
    "            dot.render(view=view)\n",
    "        return dot\n",
    "\n",
    "    @property\n",
    "    def infimum(self) -> Infimum:\n",
    "        \"\"\"The most specific concept of the lattice.\n",
    "        Returns:\n",
    "            Infimum concept of the lattice.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> lattice.infimum\n",
    "            <Infimum {} <-> [+1 -1 +2 -2 +3 -3 +sg +pl -sg -pl]>\n",
    "        \"\"\"\n",
    "        return self._concepts[0]\n",
    "\n",
    "    @property\n",
    "    def supremum(self) -> Supremum:\n",
    "        \"\"\"The most general concept of the lattice.\n",
    "        Returns:\n",
    "            Supremum concept of the lattice.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> lattice.supremum\n",
    "            <Supremum {1sg, 1pl, 2sg, 2pl, 3sg, 3pl} <-> []>\n",
    "        \"\"\"\n",
    "        return self._concepts[-1]\n",
    "\n",
    "    @property\n",
    "    def atoms(self) -> typing.Tuple[Atom, ...]:\n",
    "        \"\"\"The minimal non-infimum concepts of the lattice.\n",
    "        Returns:\n",
    "            Atom concepts of the lattice.\n",
    "        Example:\n",
    "            >>> lattice = Context.fromstring(EXAMPLE).lattice\n",
    "            >>> lattice.atoms  # doctest: +NORMALIZE_WHITESPACE\n",
    "            (<Atom {1sg} <-> [+1 -2 -3 +sg -pl] <=> 1sg>,\n",
    "             <Atom {1pl} <-> [+1 -2 -3 +pl -sg] <=> 1pl>,\n",
    "             <Atom {2sg} <-> [-1 +2 -3 +sg -pl] <=> 2sg>,\n",
    "             <Atom {2pl} <-> [-1 +2 -3 +pl -sg] <=> 2pl>,\n",
    "             <Atom {3sg} <-> [-1 -2 +3 +sg -pl] <=> 3sg>,\n",
    "             <Atom {3pl} <-> [-1 -2 +3 +pl -sg] <=> 3pl>)\n",
    "        \"\"\"\n",
    "        return self.infimum.upper_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "353311d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relations(list):\n",
    "    \"\"\"Logical relations between items from their contingent truth condition sequences.\n",
    "    >>> Relations(['+1', '-2 -3'], [(True, False, False), (True, False, False)])\n",
    "    [<Equivalent('+1', '-2 -3')>]\n",
    "    >>> Relations(['+1', '-1'], [(True, False, False), (False, True, True)])\n",
    "    [<Complement('+1', '-1')>]\n",
    "    >>> Relations(['+1', '+3'], [(True, False, False), (False, False, True)])\n",
    "    [<Incompatible('+1', '+3')>]\n",
    "    >>> Relations(['+1', '-3'], [(True, False, False), (True, True, False)])\n",
    "    [<Implication('+1', '-3')>]\n",
    "    >>> Relations(['-1', '-3'], [(False, True, True), (True, True, False)])\n",
    "    [<Subcontrary('-1', '-3')>]\n",
    "    >>> Relations(['+1', 'sg'], [(True, True, False, False), (True, False, True, False)])\n",
    "    [<Orthogonal('+1', 'sg')>]\n",
    "    >>> r = Relations(['Never', 'Always', 'Possibly', 'Maybe'],\n",
    "    ...     [(False, False), (True, True), (True, False), (True, False)],\n",
    "    ...     include_unary=True)\n",
    "    >>> r  # doctest: +NORMALIZE_WHITESPACE\n",
    "    [<Contradiction('Never')>, <Tautology('Always')>,\n",
    "     <Contingency('Possibly')>, <Contingency('Maybe')>,\n",
    "     <Equivalent('Possibly', 'Maybe')>]\n",
    "    >>> print(r)  # noqa: W291\n",
    "    Never    contradiction \n",
    "    Always   tautology    \n",
    "    Possibly contingency  \n",
    "    Maybe    contingency  \n",
    "    Possibly equivalent   Maybe\n",
    "    >>> print(r[0])\n",
    "    Never contradiction\n",
    "    >>> print(r[-1])\n",
    "    Possibly equivalent Maybe\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, items, booleans,\n",
    "                 include_unary: bool = False) -> None:\n",
    "        \"\"\"Filter out items with tautological or contradictory booleans.\"\"\"\n",
    "        unary = [Relation2(i, None, bools)\n",
    "                 for i, bools in zip(items, booleans)]\n",
    "        combos = combinations(((u.left, u.bools)\n",
    "                               for u in unary if u.__class__ is Contingency), 2)\n",
    "        binary = (Relation2(l, r, zip(lbools, rbools))\n",
    "                  for (l, lbools), (r, rbools) in combos)\n",
    "\n",
    "        members = chain(unary, binary) if include_unary else binary\n",
    "\n",
    "        super().__init__(members)\n",
    "        self.sort(key=lambda r: r.order)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return self.tostring(exclude_orthogonal=True)\n",
    "\n",
    "    def tostring(self, exclude_orthogonal: bool = False) -> str:\n",
    "        tmpl = '%%-%ds %%-12s %%s' % max(len(str(r.left)) for r in self)\n",
    "        if exclude_orthogonal:\n",
    "            self = (r for r in self if r.__class__ is not Orthogonal)\n",
    "        return '\\n'.join(tmpl % (r.left, r.kind, r.right) for r in self)\n",
    "    \n",
    "class RelationMeta(type):\n",
    "    \"\"\"Build and retrieve conrete ``Relation`` subclasses from docstring tables.\"\"\"\n",
    "\n",
    "    __map = {}\n",
    "\n",
    "    def __init__(self, name, bases, dct) -> None:\n",
    "        if 'binary' not in dct:\n",
    "            return\n",
    "\n",
    "        table = self.__doc__.strip().partition('\\n\\n')[2].strip().splitlines()\n",
    "        symbols = {'T': True, 'F': False}\n",
    "        if self.binary:\n",
    "            def get_prop(fg):\n",
    "                return tuple(symbols[f] for f in fg.strip())\n",
    "        else:\n",
    "            def get_prop(fg):\n",
    "                return symbols[fg.strip()]\n",
    "\n",
    "        properties = [get_prop(fg) for fg in table[0].strip('|').split('|')]\n",
    "        obj_flags = [(obj.split(), [bool(p.strip()) for p in props.split('|')])\n",
    "            for obj, props in (l.strip('|').partition('|')[::2] for l in table[1:])]\n",
    "\n",
    "        for index, ((name, symbol, order), symbols) in enumerate(obj_flags):\n",
    "            pattern = frozenset(p for p, f in zip(properties, symbols) if f)\n",
    "            ns = {'index': index, 'order': int(order),\n",
    "                  'kind': name.lower(), 'symbol': symbol, 'pattern': pattern}\n",
    "            cls = type(name, (self,), ns)\n",
    "            globals()[cls.__name__] = self.__map[pattern] = cls\n",
    "            __all__.append(cls.__name__)\n",
    "\n",
    "    def __call__(self, left, right, pairs):\n",
    "        self = self.__map[frozenset(pairs)]\n",
    "        if not self.binary:\n",
    "            right = pairs\n",
    "        elif self is Replication:\n",
    "            self = Implication\n",
    "            left, right = right, left\n",
    "        return super().__call__(left, right)\n",
    "\n",
    "\n",
    "class Relation2(metaclass=RelationMeta):\n",
    "    \"\"\"Logical characteristics of truth condition sequences.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "106a30ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shape(typing.NamedTuple):\n",
    "    \"\"\"Tuple of ``len(objects)`` and  ``len(properties))``.\n",
    "    Example:\n",
    "        >>> c = Context.fromstring(EXAMPLE)\n",
    "        >>> c.shape\n",
    "        Shape(objects=6, properties=10)\n",
    "        >>> n_objects, n_properties = c.shape\n",
    "        >>> n_objects, n_properties\n",
    "        (6, 10)\n",
    "    \"\"\"\n",
    "\n",
    "    objects: int\n",
    "\n",
    "    properties: int\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def _from_pair(cls, objects, properties):\n",
    "        return cls(len(objects), len(properties))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f'{self.__class__.__name__}'\n",
    "                f'(objects={self.objects:_d},'\n",
    "                f' properties={self.properties:_d})')\n",
    "\n",
    "    @property\n",
    "    def rows(self) -> int:\n",
    "        \"\"\"The number of (object) rows.\n",
    "        Example:\n",
    "            >>> c = Context.fromstring(EXAMPLE)\n",
    "            >>> c.shape.rows\n",
    "            6\n",
    "        \"\"\"\n",
    "        return self.objects\n",
    "\n",
    "    @property\n",
    "    def columns(self) -> int:\n",
    "        \"\"\"The number of (property) columns.\n",
    "        Example:\n",
    "            >>> c = Context.fromstring(EXAMPLE)\n",
    "            >>> c.shape.columns\n",
    "            10\n",
    "        \"\"\"\n",
    "        return self.properties\n",
    "\n",
    "    @property\n",
    "    def size(self) -> int:\n",
    "        \"\"\"The number of booleans (``objects * properties``).\n",
    "        Example:\n",
    "            >>> c = Context.fromstring(EXAMPLE)\n",
    "            >>> c.shape.size\n",
    "            60\n",
    "            \n",
    "        \"\"\"\n",
    "        return self.objects * self.properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cfbfbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Context():\n",
    "    \"\"\"Formal context defining a relation between objects and properties.\n",
    "    Create context from ``objects``, ``properties``, and ``bools`` correspondence.\n",
    "    Args:\n",
    "        objects: Iterable of object label strings.\n",
    "        properties: Iterable of property label strings.\n",
    "        bools: Iterable of ``len(objects)`` tuples of ``len(properties)`` booleans.\n",
    "    Returns:\n",
    "        Context: New :class:`.Context` instance.\n",
    "    Example:\n",
    "        >>> Context(['man', 'woman'], ['male', 'female'], [(True, False), (False, True)])  # doctest: +ELLIPSIS\n",
    "        <Context object mapping 2 objects to 2 properties [47e29724] at 0x...>\n",
    "    \"\"\"\n",
    "    \n",
    "    @classmethod\n",
    "    def fromstring(cls, source: str, **kwargs) -> 'Context':\n",
    "        \"\"\"Return a new context from string ``source`` in given format.\n",
    "        Args:\n",
    "            source: Formal context table as plain-text string.\n",
    "            frmat: Format of the context string (``'table'``, ``'cxt'``, ``'csv'``).\n",
    "        Returns:\n",
    "            New :class:`.Context` instance.\n",
    "        Example:\n",
    "            >>> context = Context.fromstring(EXAMPLE)\n",
    "            >>> print(context)  # doctest: +ELLIPSIS\n",
    "            <Context object mapping 6 objects to 10 properties [b9d20179] at 0x...>\n",
    "                   |+1|-1|+2|-2|+3|-3|+sg|+pl|-sg|-pl|\n",
    "                1sg|X |  |  |X |  |X |X  |   |   |X  |\n",
    "                1pl|X |  |  |X |  |X |   |X  |X  |   |\n",
    "                2sg|  |X |X |  |  |X |X  |   |   |X  |\n",
    "                2pl|  |X |X |  |  |X |   |X  |X  |   |\n",
    "                3sg|  |X |  |X |X |  |X  |   |   |X  |\n",
    "                3pl|  |X |  |X |X |  |   |X  |X  |   |\n",
    "        \"\"\"\n",
    "        with io.StringIO(source) as buf:\n",
    "            lines = (line.partition('#')[0].strip() for line in buf)\n",
    "            lines = list(filter(None, lines))\n",
    "            attributes = [a.strip() for a in lines[0].strip('|').split('|')]\n",
    "            table = [(obj.strip(), \n",
    "                tuple(bool(f.strip()) for f in flags.strip('|').split('|')))\n",
    "                for obj, flags in (objflags.partition('|')[::2] for objflags in lines[1:])]\n",
    "            objects, bools = zip(*table)\n",
    "            return cls(objects, attributes, bools)\n",
    "\n",
    "    @classmethod\n",
    "    def fromdict(cls, d: dict, ignore_lattice: bool = False,\n",
    "                 require_lattice: bool = False, raw: bool = False) -> 'Context':\n",
    "        \"\"\"Return a new context from dict ``d``.\n",
    "        Args:\n",
    "            d: serialized context with optional ``'lattice'``\n",
    "            ignore_lattice: don't load lattice from ``d``\n",
    "            require_lattice: raise if no lattice in ``d``\n",
    "            raw: If set, sort so the input sequences can be in any order.\n",
    "                 If unset (default), assume input is already ordered for speedup.\n",
    "        Returns:\n",
    "            New :class:`.Context` instance.\n",
    "        \"\"\"\n",
    "        required_keys = ('objects', 'properties', 'context')\n",
    "        try:\n",
    "            args = [d[k] for k in required_keys]\n",
    "        except KeyError:\n",
    "            missing = [k for k in required_keys if k not in d]\n",
    "            raise ValueError(f'missing required keys in fromdict: {missing!r}')\n",
    "        else:\n",
    "            objects, properties, context = args\n",
    "\n",
    "        for name, values in zip(['objects', 'properties'], args[:2]):\n",
    "            if not all(isinstance(v, str) for v in values):\n",
    "                raise ValueError(f'non-string {name} in {values!r}')\n",
    "\n",
    "        if len(context) != len(objects):\n",
    "            raise ValueError(f'mismatch: {len(objects)} objects'\n",
    "                             f' with {len(context)} context rows')\n",
    "\n",
    "        if require_lattice:\n",
    "            try:\n",
    "                lattice = d['lattice']\n",
    "            except KeyError:\n",
    "                raise ValueError('missing lattice with required_lattice')\n",
    "        else:\n",
    "            lattice = d.get('lattice')\n",
    "        if lattice is not None and not lattice:\n",
    "            raise ValueError('empty lattice')\n",
    "\n",
    "        indexes = tuple(range(len(properties)))\n",
    "\n",
    "        def _make_set(r, indexes=set(indexes)):\n",
    "            result = set(r)\n",
    "            if len(result) != len(r):\n",
    "                raise ValueError('context contains duplicated values')\n",
    "            if not result.issubset(indexes):\n",
    "                raise ValueError('context contains invalid index')\n",
    "            return result\n",
    "\n",
    "        bools = [tuple(i in intent for i in indexes)\n",
    "                 for intent in map(_make_set, context)]\n",
    "\n",
    "        inst = cls(objects, properties, bools)\n",
    "        assert 'lattice' not in inst.__dict__\n",
    "\n",
    "        if not ignore_lattice and lattice is not None:\n",
    "            inst.lattice = Lattice._fromlist(inst, lattice, raw)\n",
    "        return inst\n",
    "\n",
    "    def __init__(self,\n",
    "                 objects: typing.Iterable[str],\n",
    "                 properties: typing.Iterable[str],\n",
    "                 bools: typing.Iterable[typing.Tuple[bool, ...]]) -> None:\n",
    "        \"\"\"Create context from ``objects``, ``properties``, and ``bools`` correspondence.\n",
    "        Args:\n",
    "            objects: Iterable of object label strings.\n",
    "            properties: Iterable of property label strings.\n",
    "            bools: Iterable of ``len(objects)`` tuples of ``len(properties)`` booleans.\n",
    "        Returns:\n",
    "            ``None``.\n",
    "        Example:\n",
    "            >>> Context(['man', 'woman'],\n",
    "            ...         ['male', 'female'],\n",
    "            ...         [(True, False), (False, True)])  # doctest: +ELLIPSIS\n",
    "            <Context object mapping 2 objects to 2 properties [47e29724] at 0x...>\n",
    "        \"\"\"\n",
    "        objects, properties = map(tuple, (objects, properties))\n",
    "\n",
    "        for items, name in [(objects, 'objects'), (properties, 'properties')]:\n",
    "            if not items:\n",
    "                raise ValueError(f'empty {name}')\n",
    "            if len(set(items)) != len(items):\n",
    "                raise ValueError(f'duplicate {name}: {items!r}')\n",
    "\n",
    "        if not set(objects).isdisjoint(properties):\n",
    "            common = set(objects) & set(properties)\n",
    "            raise ValueError(f'objects and properties overlap: {common!r}')\n",
    "\n",
    "        if (len(bools) != len(objects)\n",
    "            or {len(b) for b in bools} != {len(properties)}):\n",
    "            raise ValueError(f'bools is not {len(objects)} items'\n",
    "                             f' of length {len(properties)}')\n",
    "\n",
    "        self._intents, self._extents = Relation('Properties', 'Objects', properties, objects, bools)\n",
    "\n",
    "        self._Properties = self._intents.BitSet\n",
    "        self._Objects = self._extents.BitSet\n",
    "\n",
    "    def copy(self, include_lattice: typing.Optional[bool] = False):\n",
    "        \"\"\"Return a fresh copy of the context (omits lattice).\"\"\"\n",
    "        if include_lattice:\n",
    "            raise NotImplementedError(f'.copy(include_lattice={include_lattice!r})')\n",
    "        return Context(self.objects, self.properties, self.bools)\n",
    "\n",
    "    def __getstate__(self) -> typing.Tuple[typing.Tuple[str, ...], typing.Tuple[str, ...]]:\n",
    "        \"\"\"Pickle context as ``(intents, extents)`` tuple.\n",
    "        Returns:\n",
    "            Pair of ``intents`` and ``extents``.\n",
    "        \"\"\"\n",
    "        return self._intents, self._extents\n",
    "\n",
    "    def __setstate__(self, state: typing.Tuple[typing.Tuple[str, ...], typing.Tuple[str, ...]]) -> None:\n",
    "        \"\"\"Unpickle context from ``(intents, extents)`` tuple.\n",
    "        Args:\n",
    "            state: Pair of ``intents`` and ``extents``.\n",
    "        Returns:\n",
    "            ``None``.\n",
    "        \"\"\"\n",
    "        self._intents, self._extents = state\n",
    "        self._Properties = self._intents.BitSet\n",
    "        self._Objects = self._extents.BitSet\n",
    "\n",
    "    def __eq__(self, other: 'Context') -> typing.Union[bool, type(NotImplemented)]:\n",
    "        \"\"\"Return whether two contexts are equivalent.\n",
    "        Args:\n",
    "            other: Another :class:`.Context` instance.\n",
    "        Returns:\n",
    "            ``True`` if the contexts are equal, ``False`` otherwise.\n",
    "        Example:\n",
    "            >>> context = Context.fromstring(EXAMPLE)\n",
    "            >>> context == context.copy()\n",
    "            True\n",
    "        Note:\n",
    "            Ignores ``self.lattice`` and ``other.lattice`` objects.\n",
    "        \"\"\"\n",
    "        if not isinstance(other, Context):\n",
    "            return NotImplemented\n",
    "\n",
    "        return (self.objects == other.objects\n",
    "                and self.properties == other.properties\n",
    "                and self.bools == other.bools)\n",
    "\n",
    "    def __ne__(self, other: 'Context') -> typing.Union[bool, type(NotImplemented)]:\n",
    "        \"\"\"Return whether two contexts are inequivalent.\n",
    "        Args:\n",
    "            other: Another :class:`.Context` instance.\n",
    "        Returns:\n",
    "            ``True`` if the contexts are unequal, ``False`` otherwise.\n",
    "        Example:\n",
    "            >>> context = Context.fromstring(EXAMPLE)\n",
    "            >>> definition = context.definition()\n",
    "            >>> definition['1sg', '+3'] = True\n",
    "            >>> context != Context(*definition)\n",
    "            True\n",
    "        Note:\n",
    "            Ignores ``self.lattice`` and ``other.lattice`` objects.\n",
    "        \"\"\"\n",
    "        if not isinstance(other, Context):\n",
    "            return NotImplemented\n",
    "\n",
    "        return not self == other\n",
    "\n",
    "    def __getitem__(self, items: typing.Iterable[str],\n",
    "                    raw: bool = False) -> typing.Tuple[typing.Tuple[str, ...], typing.Tuple[str, ...]]:\n",
    "        \"\"\"Return ``(extension, intension)`` pair by shared objects or properties.\n",
    "        Args:\n",
    "            items: Iterable of :obj:`str` labels either taken from ``self.objects`` or from ``self.properties``.\n",
    "            raw: Return raw ``(extent, intent)`` pair instead of :obj:`str` tuples.\n",
    "        Returns:\n",
    "            The smallest concept having all ``items`` as ``(extent, intent)`` pair.\n",
    "        Example:\n",
    "            >>> context = Context.fromstring(EXAMPLE)\n",
    "            >>> context['1sg',]\n",
    "            (('1sg',), ('+1', '-2', '-3', '+sg', '-pl'))\n",
    "            >>> context['1sg', '1pl', '2pl']\n",
    "            (('1sg', '1pl', '2sg', '2pl'), ('-3',))\n",
    "            >>> context['-1', '-sg']\n",
    "            (('2pl', '3pl'), ('-1', '+pl', '-sg'))\n",
    "        \"\"\"\n",
    "        try:\n",
    "            extent = self._Objects.frommembers(items)\n",
    "        except KeyError:\n",
    "            intent = self._Properties.frommembers(items)\n",
    "            intent, extent = intent.doubleprime()\n",
    "        else:\n",
    "            extent, intent = extent.doubleprime()\n",
    "\n",
    "        if raw:\n",
    "            return extent, intent\n",
    "        return extent.members(), intent.members()\n",
    "\n",
    "    def intension(self, objects: typing.Iterable[str], raw: bool = False) -> typing.Tuple[str, ...]:\n",
    "        \"\"\"Return all properties shared by the given ``objects``.\n",
    "        Args:\n",
    "            objects: Iterable of :obj:`str` labels taken from ``self.objects``.\n",
    "            raw: Return raw intent instead of :obj:`str` tuple.\n",
    "        Returns:\n",
    "            A tuple of :obj:`str` labels taken from ``self.properties``.\n",
    "        Example:\n",
    "            >>> context = Context.fromstring(EXAMPLE)\n",
    "            >>> context.intension(['1sg'])\n",
    "            ('+1', '-2', '-3', '+sg', '-pl')\n",
    "        \"\"\"\n",
    "        intent = self._Objects.frommembers(objects).prime()\n",
    "        if raw:\n",
    "            return intent\n",
    "        return intent.members()\n",
    "\n",
    "    def extension(self, properties: typing.Iterable[str], raw: bool = False) -> typing.Tuple[str, ...]:\n",
    "        \"\"\"Return all objects sharing the given ``properties``.\n",
    "        Args:\n",
    "            properties: Iterable of :obj:`str` labels taken from ``self.properties``.\n",
    "            raw: Return raw extent instead of :obj:`str` tuple.\n",
    "        Returns:\n",
    "            A tuple of :obj:`str` labels taken from ``self.objects``.\n",
    "        Example:\n",
    "            >>> context = Context.fromstring(EXAMPLE)\n",
    "            >>> context.extension(['+1'])\n",
    "            ('1sg', '1pl')\n",
    "        \"\"\"\n",
    "        extent = self._Properties.frommembers(properties).prime()\n",
    "        if raw:\n",
    "            return extent\n",
    "        return extent.members()\n",
    "\n",
    "    @classmethod\n",
    "    def _minimal(cls, extent, intent):\n",
    "        \"\"\"Return short lexicograpically minimum intent generating extent.\"\"\"\n",
    "        return next(cls._minimize(extent, intent))\n",
    "\n",
    "    @staticmethod\n",
    "    def _minimize(extent, intent):\n",
    "        \"\"\"Yield short lexicograpically ordered extent generating intents.\"\"\"\n",
    "        if not extent:\n",
    "            yield intent\n",
    "            return\n",
    "\n",
    "        for it in intent.powerset():\n",
    "            if it.prime() == extent:\n",
    "                yield it\n",
    "\n",
    "    def _lattice(self, infimum=()):\n",
    "        \"\"\"Yield ``(extent, intent, upper, lower)`` in short lexicographic order.\n",
    "        \"\"\"\n",
    "        def neighbors(objects, Objects):\n",
    "            doubleprime = Objects.doubleprime\n",
    "\n",
    "            minimal = ~objects\n",
    "\n",
    "            for add in Objects.atomic(minimal):\n",
    "                objects_and_add = objects | add\n",
    "\n",
    "                extent, intent = doubleprime(objects_and_add)\n",
    "\n",
    "                if extent & ~objects_and_add & minimal:\n",
    "                    minimal &= ~add\n",
    "                else:\n",
    "                    yield extent, intent\n",
    "        \n",
    "        extent, intent = self._Objects.frommembers(infimum).doubleprime()\n",
    "\n",
    "        concept = (extent, intent, [], [])\n",
    "\n",
    "        mapping = {extent: concept}\n",
    "\n",
    "        heap = [(extent.shortlex(), concept)]\n",
    "\n",
    "        push = functools.partial(heapq.heappush, heap)\n",
    "        pop = functools.partial(heapq.heappop, heap)\n",
    "\n",
    "        while heap:\n",
    "            _, concept = pop()\n",
    "\n",
    "            extent, _, upper, _ = concept\n",
    "\n",
    "            for n_extent, n_intent in neighbors(extent, self._Objects):\n",
    "                upper.append(n_extent)\n",
    "\n",
    "                if n_extent in mapping:\n",
    "                    mapping[n_extent][3].append(extent)\n",
    "                else:\n",
    "                    mapping[n_extent] = neighbor = (n_extent, n_intent, [], [extent])\n",
    "                    push((n_extent.shortlex(), neighbor))\n",
    "\n",
    "            yield concept\n",
    "\n",
    "    def _neighbors(self, objects):\n",
    "        \"\"\"Yield upper neighbors from extent (in colex order?).\n",
    "        \"\"\"\n",
    "        doubleprime = self._Objects.doubleprime\n",
    "        \n",
    "        minimal = ~objects\n",
    "\n",
    "        for add in self._Objects.atomic(minimal):\n",
    "            objects_and_add = objects | add\n",
    "\n",
    "            extent, intent = doubleprime(objects_and_add)\n",
    "\n",
    "            if extent & ~objects_and_add & minimal:\n",
    "                minimal &= ~add\n",
    "            else:\n",
    "                yield extent, intent\n",
    "\n",
    "    def neighbors(self, objects: typing.Iterable[str],\n",
    "                  raw: bool = False) -> typing.List[typing.Tuple[typing.Tuple[str, ...],\n",
    "                                                                 typing.Tuple[str, ...]]]:\n",
    "        \"\"\"Return the upper neighbors of the concept having all given ``objects``.\n",
    "        Args:\n",
    "            objects: Iterable of :obj:`str` labels taken from ``self.objects``.\n",
    "            raw: Return raw ``(extent, intent)`` pairs instead of :obj:`str` tuples.\n",
    "        Returns:\n",
    "            A list of upper neighbor concepts as ``(extent, intent)`` pairs.\n",
    "        Example:\n",
    "            >>> context = Context.fromstring(EXAMPLE)\n",
    "            >>> context.neighbors(['1sg', '1pl', '2pl'])\n",
    "            [(('1sg', '1pl', '2sg', '2pl', '3sg', '3pl'), ())]\n",
    "        \"\"\"\n",
    "        objects = self._Objects.frommembers(objects).double()\n",
    "        if raw:\n",
    "            return list(self._neighbors(objects))\n",
    "        return [(extent.members(), intent.members())\n",
    "                for extent, intent in self._neighbors(objects)]\n",
    "\n",
    "    @lazyproperty\n",
    "    def lattice(self) -> 'Lattice':\n",
    "        \"\"\"The concept lattice of the formal context.\n",
    "        Returns:\n",
    "             Lattice: Cached or new :class:`Lattice` instance.\n",
    "        \"\"\"\n",
    "        return Lattice(self)\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"Return the full string representation of the context.\n",
    "        Returns:\n",
    "            The ``repr()`` of the context  followed by its table representation.\n",
    "        Example:\n",
    "            >>> context = Context.fromstring(EXAMPLE)\n",
    "            >>> print(context)\n",
    "            <Context object mapping 6 objects to 10 properties [b9d20179] at 0x...>\n",
    "                   |+1|-1|+2|-2|+3|-3|+sg|+pl|-sg|-pl|\n",
    "                1sg|X |  |  |X |  |X |X  |   |   |X  |\n",
    "                1pl|X |  |  |X |  |X |   |X  |X  |   |\n",
    "                2sg|  |X |X |  |  |X |X  |   |   |X  |\n",
    "                2pl|  |X |X |  |  |X |   |X  |X  |   |\n",
    "                3sg|  |X |  |X |X |  |X  |   |   |X  |\n",
    "                3pl|  |X |  |X |X |  |   |X  |X  |   |\n",
    "        \"\"\"\n",
    "        return (f'{self!r}\\n'\n",
    "                f'{self.tostring(indent=4)}')\n",
    "\n",
    "    def tostring(self, frmat: str = 'table', **kwargs) -> str:\n",
    "        \"\"\"Return the context serialized in the given string-based format.\n",
    "        Args:\n",
    "            frmat: Format of the string (``'table'``, ``'cxt'``, ``'csv'``).\n",
    "        Returns:\n",
    "            The context as seralized string.\n",
    "        \"\"\"\n",
    "        wd = [0]\n",
    "        try:\n",
    "            result = max(map(len, self.objects))\n",
    "            wd = [max(result, 0)]\n",
    "        except ValueError:\n",
    "            wd = [0]\n",
    "        wd.extend(map(len, self.properties))\n",
    "        tmpl = ' ' * 0 + '|'.join(f'%-{w:d}s' for w in wd) + '|'\n",
    "        write = functools.partial(print)\n",
    "        write(tmpl % (('',) + tuple(self.properties)))\n",
    "        for o, intent in zip(self.objects, self.bools):\n",
    "            write(tmpl % ((o,) + tuple('X' if b else '' for b in intent)))\n",
    "\n",
    "    def todict(self, ignore_lattice: bool = False\n",
    "               ) -> typing.Dict[str,\n",
    "                                typing.Union[typing.Tuple[str, ...],\n",
    "                                             typing.List[typing.Tuple[int, ...]],\n",
    "                                             typing.List[typing.Tuple[typing.Tuple[int, ...],\n",
    "                                                                      typing.Tuple[int, ...],\n",
    "                                                                      typing.Tuple[int, ...],\n",
    "                                                                      typing.Tuple[int, ...]]]]]:\n",
    "        \"\"\"Return serialized context with optional lattice.\n",
    "        Args:\n",
    "            ingnore_lattice: Omit ``'lattice'`` in result.\n",
    "                If ``None``, ``'lattice'`` is omitted if it has not\n",
    "                yet been computed.\n",
    "        Returns:\n",
    "            A new :obj:`dict` with the serialized context.\n",
    "        Example:\n",
    "            >>> context = Context.fromstring(EXAMPLE)\n",
    "            >>> context.todict()  # doctest: +NORMALIZE_WHITESPACE\n",
    "            {'objects': ('1sg', '1pl', '2sg', '2pl', '3sg', '3pl'),\n",
    "             'properties': ('+1', '-1', '+2', '-2', '+3', '-3', '+sg', '+pl', '-sg', '-pl'),\n",
    "             'context': [(0, 3, 5, 6, 9),\n",
    "                         (0, 3, 5, 7, 8),\n",
    "                         (1, 2, 5, 6, 9),\n",
    "                         (1, 2, 5, 7, 8),\n",
    "                         (1, 3, 4, 6, 9),\n",
    "                         (1, 3, 4, 7, 8)],\n",
    "             'lattice': [((), (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), (1, 2, 3, 4, 5, 6), ()),\n",
    "                         ((0,), (0, 3, 5, 6, 9), (7, 8, 9), (0,)),\n",
    "                         ((1,), (0, 3, 5, 7, 8), (7, 10, 11), (0,)),\n",
    "                         ((2,), (1, 2, 5, 6, 9), (8, 12, 13), (0,)),\n",
    "                         ((3,), (1, 2, 5, 7, 8), (10, 12, 14), (0,)),\n",
    "                         ((4,), (1, 3, 4, 6, 9), (9, 13, 15), (0,)),\n",
    "                         ((5,), (1, 3, 4, 7, 8), (11, 14, 15), (0,)),\n",
    "                         ((0, 1), (0, 3, 5), (18, 19), (1, 2)),\n",
    "                         ((0, 2), (5, 6, 9), (16, 18), (1, 3)),\n",
    "                         ((0, 4), (3, 6, 9), (16, 19), (1, 5)),\n",
    "                         ((1, 3), (5, 7, 8), (17, 18), (2, 4)),\n",
    "                         ((1, 5), (3, 7, 8), (17, 19), (2, 6)),\n",
    "                         ((2, 3), (1, 2, 5), (18, 20), (3, 4)),\n",
    "                         ((2, 4), (1, 6, 9), (16, 20), (3, 5)),\n",
    "                         ((3, 5), (1, 7, 8), (17, 20), (4, 6)),\n",
    "                         ((4, 5), (1, 3, 4), (19, 20), (5, 6)),\n",
    "                         ((0, 2, 4), (6, 9), (21,), (8, 9, 13)),\n",
    "                         ((1, 3, 5), (7, 8), (21,), (10, 11, 14)),\n",
    "                         ((0, 1, 2, 3), (5,), (21,), (7, 8, 10, 12)),\n",
    "                         ((0, 1, 4, 5), (3,), (21,), (7, 9, 11, 15)),\n",
    "                         ((2, 3, 4, 5), (1,), (21,), (12, 13, 14, 15)),\n",
    "                         ((0, 1, 2, 3, 4, 5), (), (), (18, 19, 20, 16, 17))]}\n",
    "        \"\"\"\n",
    "        result = {'objects': self.objects,\n",
    "                  'properties': self.properties,\n",
    "                  'context': self._intents.index_sets()}\n",
    "        if ignore_lattice:\n",
    "            pass\n",
    "        elif ignore_lattice is None and 'lattice' not in self.__dict__:\n",
    "            pass\n",
    "        else:\n",
    "            result['lattice'] = self.lattice._tolist()\n",
    "        return result\n",
    "\n",
    "    @property\n",
    "    def objects(self) -> typing.Tuple[str, ...]:\n",
    "        \"\"\"(Names of the) objects described by the context.\n",
    "        Returns:\n",
    "            Context object labels.\n",
    "        Example:\n",
    "            >>> context = Context.fromstring(EXAMPLE)\n",
    "            >>> context.objects\n",
    "            ('1sg', '1pl', '2sg', '2pl', '3sg', '3pl')\n",
    "        \"\"\"\n",
    "        return self._Objects._members\n",
    "\n",
    "    @property\n",
    "    def properties(self) -> typing.Tuple[str, ...]:\n",
    "        \"\"\"(Names of the) properties that describe the objects.\n",
    "        Returns:\n",
    "            Context property labels.\n",
    "        Example:\n",
    "            >>> import concepts\n",
    "            >>> context = concepts.Context.fromstring(concepts.EXAMPLE)\n",
    "            >>> context.properties\n",
    "            ('+1', '-1', '+2', '-2', '+3', '-3', '+sg', '+pl', '-sg', '-pl')\n",
    "        \"\"\"\n",
    "        return self._Properties._members\n",
    "\n",
    "    @property\n",
    "    def bools(self) -> typing.List[typing.Tuple[bool, ...]]:\n",
    "        \"\"\"Row-wise boolean relation matrix between objects and properties.\n",
    "        Returns:\n",
    "            Table with the relation between context ``objects`` and ``properties``.\n",
    "        Example:\n",
    "            >>> context = Context.fromstring(EXAMPLE)\n",
    "            >>> context.bools  # doctest: +NORMALIZE_WHITESPACE\n",
    "            [(True, False, False, True, False, True, True, False, False, True),\n",
    "             (True, False, False, True, False, True, False, True, True, False),\n",
    "             (False, True, True, False, False, True, True, False, False, True),\n",
    "             (False, True, True, False, False, True, False, True, True, False),\n",
    "             (False, True, False, True, True, False, True, False, False, True),\n",
    "             (False, True, False, True, True, False, False, True, True, False)]\n",
    "            \"\"\"\n",
    "        return self._intents.bools()\n",
    "\n",
    "    @lazyproperty\n",
    "    def shape(self) -> Shape:\n",
    "        \"\"\"The shape/dimensions of the context.\n",
    "        Returns:\n",
    "            :class:`.Shape` instance.\n",
    "        Example:\n",
    "            >>> context = Context.fromstring(EXAMPLE)\n",
    "            >>> context.shape\n",
    "            Shape(objects=6, properties=10)\n",
    "        \"\"\"\n",
    "        return Shape._from_pair(self.objects, self.properties)\n",
    "\n",
    "    @lazyproperty\n",
    "    def fill_ratio(self) -> fractions.Fraction:\n",
    "        \"\"\"The fill ratio (density of ``True`` values) of the context.\n",
    "        Fill ratio 0.25 means that 25% of the values in ``self.bools``\n",
    "        are ``True`` values.\n",
    "        Returns:\n",
    "            Context fill ratio (can be interpreted as percentages).\n",
    "        Example:\n",
    "            >>> context = Context.fromstring(EXAMPLE)\n",
    "            >>> float(context.fill_ratio)\n",
    "            0.5\n",
    "            >>> context.fill_ratio\n",
    "            Fraction(1, 2)\n",
    "        \"\"\"\n",
    "        n_true = sum(intent.count() for intent in self._intents)\n",
    "        return fractions.Fraction(n_true, self.shape.size)\n",
    "\n",
    "    def definition(self) -> typing.Tuple[typing.Tuple, typing.Tuple, typing.List]:\n",
    "        return (self.objects, self.attributes, self.bools)\n",
    "\n",
    "    def relations(self, include_unary: bool = False) -> 'Relations':\n",
    "        \"\"\"Return the logical relations between the context properties.\n",
    "        Args:\n",
    "            include_unary: Include unary relations in result.\n",
    "        Returns:\n",
    "            Collection of binary (and optionally unary) logical relations.\n",
    "        Example:\n",
    "            >>> import concepts\n",
    "            >>> context = concepts.Context.fromstring(concepts.EXAMPLE)\n",
    "            >>> print(context.relations())\n",
    "            +sg equivalent   -pl\n",
    "            +pl equivalent   -sg\n",
    "            +1  complement   -1\n",
    "            +2  complement   -2\n",
    "            +3  complement   -3\n",
    "            +sg complement   +pl\n",
    "            +sg complement   -sg\n",
    "            +pl complement   -pl\n",
    "            -sg complement   -pl\n",
    "            +1  incompatible +2\n",
    "            +1  incompatible +3\n",
    "            +2  incompatible +3\n",
    "            +1  implication  -2\n",
    "            +1  implication  -3\n",
    "            +2  implication  -1\n",
    "            +3  implication  -1\n",
    "            +2  implication  -3\n",
    "            +3  implication  -2\n",
    "            -1  subcontrary  -2\n",
    "            -1  subcontrary  -3\n",
    "            -2  subcontrary  -3\n",
    "        \"\"\"\n",
    "        return Relations(self.properties, self._extents.bools(), include_unary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70daf4a",
   "metadata": {},
   "source": [
    "## Example with arXiv.ord data\n",
    "\n",
    "### First of all\n",
    "\n",
    "Download data from https://www.kaggle.com/datasets/Cornell-University/arxiv and put file .json with jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16c76297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "060dcd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = []\n",
    "    for line in open(filename, 'r'):\n",
    "        data.append(json.loads(line))\n",
    "    df = pd.DataFrame.from_records(data)\n",
    "    df = df[['title', 'abstract']].drop_duplicates()\n",
    "    return df\n",
    "\n",
    "def get_context(dataframe, max_objects_count=None, max_properties_count=None):\n",
    "    if max_objects_count:\n",
    "        dataframe = dataframe.sample(max_objects_count)\n",
    "        \n",
    "    objects = tuple(title[:30] + '...' for title in dataframe.title)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "    X = vectorizer.fit_transform(dataframe.abstract)\n",
    "    \n",
    "    properties = tuple(vectorizer.get_feature_names_out())\n",
    "    \n",
    "    if max_properties_count:\n",
    "        feature_array = np.array(vectorizer.get_feature_names_out())\n",
    "        properties = tuple(feature_array[np.argsort(X.toarray()).flatten()[::-1]][:max_properties_count])\n",
    "        \n",
    "    context = []\n",
    "    for abstract in dataframe.abstract:\n",
    "        row = []\n",
    "        for word in abstract.lower().split():\n",
    "            try :\n",
    "                pos = properties.index(word)\n",
    "                row.append(pos)\n",
    "            except ValueError as e:\n",
    "                pass\n",
    "        context.append(tuple(set(row)))\n",
    "            \n",
    "    return (objects, properties, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b4178a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data('arxiv-metadata-oai-snapshot.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70db4fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 8.0.3 (20230416.2022)\n",
       " -->\n",
       "<!-- Title: Lattice Pages: 1 -->\n",
       "<svg width=\"1215pt\" height=\"407pt\"\n",
       " viewBox=\"0.00 0.00 1215.00 407.09\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 403.09)\">\n",
       "<title>Lattice</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-403.09 1211,-403.09 1211,4 -4,4\"/>\n",
       "<!-- c0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>c0</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"528.6\" cy=\"-9.09\" rx=\"9\" ry=\"9\"/>\n",
       "</g>\n",
       "<!-- c0&#45;&gt;c0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>c0&#45;&gt;c0</title>\n",
       "<path fill=\"none\" stroke=\"none\" d=\"M535.79,-15.07C544.83,-19.88 555.6,-17.89 555.6,-9.09 555.6,-0.29 544.83,1.7 535.79,-3.11\"/>\n",
       "<text text-anchor=\"middle\" x=\"529.63\" y=\"-25.05\" font-family=\"Times,serif\" font-size=\"14.00\">core collapse tau mu ray particular wimps supernovae</text>\n",
       "</g>\n",
       "<!-- c1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>c1</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"528.6\" cy=\"-100.09\" rx=\"9\" ry=\"9\"/>\n",
       "</g>\n",
       "<!-- c1&#45;&gt;c0 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>c1&#45;&gt;c0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M528.6,-90.88C528.6,-74.01 528.6,-35.61 528.6,-18.54\"/>\n",
       "</g>\n",
       "<!-- c1&#45;&gt;c1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>c1&#45;&gt;c1</title>\n",
       "<path fill=\"none\" stroke=\"none\" d=\"M537.45,-103.48C546.1,-105.35 555.6,-104.22 555.6,-100.09 555.6,-95.96 546.1,-94.83 537.45,-96.7\"/>\n",
       "<text text-anchor=\"middle\" x=\"534.78\" y=\"-78.24\" font-family=\"Times,serif\" font-size=\"14.00\">Pulsar&#45;driven Jets in Supernov...</text>\n",
       "</g>\n",
       "<!-- c1&#45;&gt;c1 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>c1&#45;&gt;c1</title>\n",
       "<path fill=\"none\" stroke=\"none\" d=\"M536.56,-104.59C552.24,-111.19 573.6,-109.69 573.6,-100.09 573.6,-90.49 552.24,-88.99 536.56,-95.59\"/>\n",
       "</g>\n",
       "<!-- c2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>c2</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"456.6\" cy=\"-100.09\" rx=\"9\" ry=\"9\"/>\n",
       "</g>\n",
       "<!-- c2&#45;&gt;c0 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>c2&#45;&gt;c0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M462.01,-92.4C475.49,-75.75 510.39,-32.6 523.51,-16.38\"/>\n",
       "</g>\n",
       "<!-- c2&#45;&gt;c2 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>c2&#45;&gt;c2</title>\n",
       "<path fill=\"none\" stroke=\"none\" d=\"M465.45,-103.48C474.1,-105.35 483.6,-104.22 483.6,-100.09 483.6,-95.96 474.1,-94.83 465.45,-96.7\"/>\n",
       "<text text-anchor=\"middle\" x=\"462.78\" y=\"-78.24\" font-family=\"Times,serif\" font-size=\"14.00\">Near&#45;Earth Supernova Explosion...</text>\n",
       "</g>\n",
       "<!-- c2&#45;&gt;c2 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>c2&#45;&gt;c2</title>\n",
       "<path fill=\"none\" stroke=\"none\" d=\"M464.56,-104.59C480.24,-111.19 501.6,-109.69 501.6,-100.09 501.6,-90.49 480.24,-88.99 464.56,-95.59\"/>\n",
       "</g>\n",
       "<!-- c3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>c3</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"600.6\" cy=\"-100.09\" rx=\"9\" ry=\"9\"/>\n",
       "</g>\n",
       "<!-- c3&#45;&gt;c0 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>c3&#45;&gt;c0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M595.19,-92.4C581.71,-75.75 546.81,-32.6 533.69,-16.38\"/>\n",
       "</g>\n",
       "<!-- c3&#45;&gt;c3 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>c3&#45;&gt;c3</title>\n",
       "<path fill=\"none\" stroke=\"none\" d=\"M609.45,-103.48C618.1,-105.35 627.6,-104.22 627.6,-100.09 627.6,-95.96 618.1,-94.83 609.45,-96.7\"/>\n",
       "<text text-anchor=\"middle\" x=\"606.78\" y=\"-78.24\" font-family=\"Times,serif\" font-size=\"14.00\">Impact of sterile neutrino dar...</text>\n",
       "</g>\n",
       "<!-- c3&#45;&gt;c3 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>c3&#45;&gt;c3</title>\n",
       "<path fill=\"none\" stroke=\"none\" d=\"M608.56,-104.59C624.24,-111.19 645.6,-109.69 645.6,-100.09 645.6,-90.49 624.24,-88.99 608.56,-95.59\"/>\n",
       "<text text-anchor=\"middle\" x=\"603.5\" y=\"-115.01\" font-family=\"Times,serif\" font-size=\"14.00\">sterile neutrino neutrinos mixing kev matter effect observable comprises decaying candidates recent electron oscillations total indicated luminosities realistic does significant summarize explore fraction angles angle small</text>\n",
       "</g>\n",
       "<!-- c4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>c4</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"433.6\" cy=\"-191.09\" rx=\"9\" ry=\"9\"/>\n",
       "</g>\n",
       "<!-- c4&#45;&gt;c1 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>c4&#45;&gt;c1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M439.83,-184.25C457.01,-168.16 504.87,-123.32 522.22,-107.07\"/>\n",
       "</g>\n",
       "<!-- c4&#45;&gt;c2 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>c4&#45;&gt;c2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M428.71,-183.31C422.94,-174.45 414.72,-158.47 419.6,-145.09 425.62,-128.59 440.85,-113.98 449.78,-106.46\"/>\n",
       "</g>\n",
       "<!-- c4&#45;&gt;c4 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>c4&#45;&gt;c4</title>\n",
       "<path fill=\"none\" stroke=\"none\" d=\"M440.79,-197.07C449.83,-201.88 460.6,-199.89 460.6,-191.09 460.6,-182.29 449.83,-180.3 440.79,-185.11\"/>\n",
       "<text text-anchor=\"middle\" x=\"434.63\" y=\"-207.05\" font-family=\"Times,serif\" font-size=\"14.00\">explosions</text>\n",
       "</g>\n",
       "<!-- c5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>c5</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"557.6\" cy=\"-191.09\" rx=\"9\" ry=\"9\"/>\n",
       "</g>\n",
       "<!-- c5&#45;&gt;c1 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>c5&#45;&gt;c1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M555.03,-182.19C549.54,-165.35 536.73,-126.04 531.21,-109.1\"/>\n",
       "</g>\n",
       "<!-- c5&#45;&gt;c3 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>c5&#45;&gt;c3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M561.27,-182.5C569.39,-165.69 588.83,-125.46 596.94,-108.66\"/>\n",
       "</g>\n",
       "<!-- c5&#45;&gt;c5 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>c5&#45;&gt;c5</title>\n",
       "<path fill=\"none\" stroke=\"none\" d=\"M564.79,-197.07C573.83,-201.88 584.6,-199.89 584.6,-191.09 584.6,-182.29 573.83,-180.3 564.79,-185.11\"/>\n",
       "<text text-anchor=\"middle\" x=\"558.63\" y=\"-207.05\" font-family=\"Times,serif\" font-size=\"14.00\">dark</text>\n",
       "</g>\n",
       "<!-- c6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>c6</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"589.6\" cy=\"-245.09\" rx=\"9\" ry=\"9\"/>\n",
       "</g>\n",
       "<!-- c6&#45;&gt;c3 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>c6&#45;&gt;c3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M590.42,-235.66C591.26,-226.81 592.6,-212.48 593.6,-200.09 596.31,-166.6 598.95,-126.69 600.06,-109.57\"/>\n",
       "</g>\n",
       "<!-- c6&#45;&gt;c6 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>c6&#45;&gt;c6</title>\n",
       "<path fill=\"none\" stroke=\"none\" d=\"M598.17,-249.04C606.89,-251.36 616.6,-250.05 616.6,-245.09 616.6,-240.13 606.89,-238.82 598.17,-241.14\"/>\n",
       "<text text-anchor=\"middle\" x=\"594.9\" y=\"-222.8\" font-family=\"Times,serif\" font-size=\"14.00\">The SETI Episode in the 1967 D...</text>\n",
       "</g>\n",
       "<!-- c6&#45;&gt;c6 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>c6&#45;&gt;c6</title>\n",
       "<path fill=\"none\" stroke=\"none\" d=\"M597.12,-250.21C612.84,-258.29 634.6,-256.59 634.6,-245.09 634.6,-233.59 612.84,-231.89 597.12,-239.97\"/>\n",
       "<text text-anchor=\"middle\" x=\"591.11\" y=\"-260.25\" font-family=\"Times,serif\" font-size=\"14.00\">consider</text>\n",
       "</g>\n",
       "<!-- c7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>c7</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"503.6\" cy=\"-191.09\" rx=\"9\" ry=\"9\"/>\n",
       "</g>\n",
       "<!-- c7&#45;&gt;c2 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>c7&#45;&gt;c2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M499.59,-182.5C490.71,-165.69 469.47,-125.46 460.6,-108.66\"/>\n",
       "</g>\n",
       "<!-- c7&#45;&gt;c3 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>c7&#45;&gt;c3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M509.96,-184.25C527.67,-168.01 577.32,-122.45 594.59,-106.61\"/>\n",
       "</g>\n",
       "<!-- c7&#45;&gt;c7 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>c7&#45;&gt;c7</title>\n",
       "<path fill=\"none\" stroke=\"none\" d=\"M510.79,-197.07C519.83,-201.88 530.6,-199.89 530.6,-191.09 530.6,-182.29 519.83,-180.3 510.79,-185.11\"/>\n",
       "<text text-anchor=\"middle\" x=\"504.63\" y=\"-207.05\" font-family=\"Times,serif\" font-size=\"14.00\">impact</text>\n",
       "</g>\n",
       "<!-- c8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>c8</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"661.6\" cy=\"-245.09\" rx=\"9\" ry=\"9\"/>\n",
       "</g>\n",
       "<!-- c8&#45;&gt;c3 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>c8&#45;&gt;c3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M658.32,-236.4C647.73,-211.57 614.51,-133.7 603.9,-108.82\"/>\n",
       "</g>\n",
       "<!-- c8&#45;&gt;c8 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>c8&#45;&gt;c8</title>\n",
       "<path fill=\"none\" stroke=\"none\" d=\"M670.17,-249.04C678.89,-251.36 688.6,-250.05 688.6,-245.09 688.6,-240.13 678.89,-238.82 670.17,-241.14\"/>\n",
       "<text text-anchor=\"middle\" x=\"666.9\" y=\"-222.8\" font-family=\"Times,serif\" font-size=\"14.00\">Unbiased simulation of structu...</text>\n",
       "</g>\n",
       "<!-- c8&#45;&gt;c8 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>c8&#45;&gt;c8</title>\n",
       "<path fill=\"none\" stroke=\"none\" d=\"M669.12,-250.21C684.84,-258.29 706.6,-256.59 706.6,-245.09 706.6,-233.59 684.84,-231.89 669.12,-239.97\"/>\n",
       "<text text-anchor=\"middle\" x=\"663.11\" y=\"-260.25\" font-family=\"Times,serif\" font-size=\"14.00\">case</text>\n",
       "</g>\n",
       "<!-- c9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>c9</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"524.6\" cy=\"-299.09\" rx=\"9\" ry=\"9\"/>\n",
       "</g>\n",
       "<!-- c9&#45;&gt;c4 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>c9&#45;&gt;c4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M519.18,-291.78C503.03,-272.97 455.37,-217.44 439.11,-198.5\"/>\n",
       "</g>\n",
       "<!-- c9&#45;&gt;c5 -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>c9&#45;&gt;c5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M527.08,-290.12C533.2,-270.48 548.94,-219.89 555.09,-200.15\"/>\n",
       "</g>\n",
       "<!-- c9&#45;&gt;c7 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>c9&#45;&gt;c7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M522.95,-289.77C519.03,-269.96 509.16,-220.15 505.24,-200.37\"/>\n",
       "</g>\n",
       "<!-- c9&#45;&gt;c9 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>c9&#45;&gt;c9</title>\n",
       "<path fill=\"none\" stroke=\"none\" d=\"M531.79,-305.07C540.83,-309.88 551.6,-307.89 551.6,-299.09 551.6,-290.29 540.83,-288.3 531.79,-293.11\"/>\n",
       "<text text-anchor=\"middle\" x=\"525.63\" y=\"-315.05\" font-family=\"Times,serif\" font-size=\"14.00\">supernova</text>\n",
       "</g>\n",
       "<!-- c10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>c10</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"589.6\" cy=\"-390.09\" rx=\"9\" ry=\"9\"/>\n",
       "</g>\n",
       "<!-- c10&#45;&gt;c6 -->\n",
       "<g id=\"edge32\" class=\"edge\">\n",
       "<title>c10&#45;&gt;c6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M589.6,-380.99C589.6,-355.94 589.6,-279.87 589.6,-254.46\"/>\n",
       "</g>\n",
       "<!-- c10&#45;&gt;c8 -->\n",
       "<g id=\"edge33\" class=\"edge\">\n",
       "<title>c10&#45;&gt;c8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M593.27,-381.8C605.59,-357.33 645.41,-278.24 657.85,-253.53\"/>\n",
       "</g>\n",
       "<!-- c10&#45;&gt;c9 -->\n",
       "<g id=\"edge34\" class=\"edge\">\n",
       "<title>c10&#45;&gt;c9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M584.5,-382.11C572.29,-365.39 541.5,-323.23 529.5,-306.8\"/>\n",
       "</g>\n",
       "<!-- c10&#45;&gt;c10 -->\n",
       "<g id=\"edge30\" class=\"edge\">\n",
       "<title>c10&#45;&gt;c10</title>\n",
       "<path fill=\"none\" stroke=\"none\" d=\"M598.45,-393.48C607.1,-395.35 616.6,-394.22 616.6,-390.09 616.6,-385.96 607.1,-384.83 598.45,-386.7\"/>\n",
       "<text text-anchor=\"middle\" x=\"595.78\" y=\"-368.24\" font-family=\"Times,serif\" font-size=\"14.00\">Testing macroscopic realism th... A white noise approach to stoc... Fundamental Molecules of Life ... Entropy&#45;based measure of struc... A C&#45;system defined by a univer...</text>\n",
       "</g>\n",
       "<!-- c10&#45;&gt;c10 -->\n",
       "<g id=\"edge31\" class=\"edge\">\n",
       "<title>c10&#45;&gt;c10</title>\n",
       "<path fill=\"none\" stroke=\"none\" d=\"M597.56,-394.59C613.24,-401.19 634.6,-399.69 634.6,-390.09 634.6,-380.49 613.24,-378.99 597.56,-385.59\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x159feb7f0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects, properties, context = get_context(df, max_objects_count=10, max_properties_count=40)\n",
    "d = {'objects': objects,\n",
    "     'properties': properties,\n",
    "     'context': context}\n",
    "context = Context.fromdict(d)\n",
    "context.lattice.graphviz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75cc7302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Pulsar-driven Jets in Supernov...',\n",
       " 'Testing macroscopic realism th...',\n",
       " 'The SETI Episode in the 1967 D...',\n",
       " 'A white noise approach to stoc...',\n",
       " 'Fundamental Molecules of Life ...',\n",
       " 'Entropy-based measure of struc...',\n",
       " 'A C-system defined by a univer...',\n",
       " 'Near-Earth Supernova Explosion...',\n",
       " 'Unbiased simulation of structu...',\n",
       " 'Impact of sterile neutrino dar...')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4dbf9ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sterile',\n",
       " 'neutrino',\n",
       " 'neutrinos',\n",
       " 'mixing',\n",
       " 'dark',\n",
       " 'kev',\n",
       " 'core',\n",
       " 'collapse',\n",
       " 'matter',\n",
       " 'supernova',\n",
       " 'effect',\n",
       " 'observable',\n",
       " 'comprises',\n",
       " 'tau',\n",
       " 'decaying',\n",
       " 'mu',\n",
       " 'impact',\n",
       " 'consider',\n",
       " 'case',\n",
       " 'explosions',\n",
       " 'ray',\n",
       " 'candidates',\n",
       " 'recent',\n",
       " 'electron',\n",
       " 'oscillations',\n",
       " 'total',\n",
       " 'indicated',\n",
       " 'luminosities',\n",
       " 'particular',\n",
       " 'realistic',\n",
       " 'does',\n",
       " 'significant',\n",
       " 'summarize',\n",
       " 'wimps',\n",
       " 'explore',\n",
       " 'supernovae',\n",
       " 'fraction',\n",
       " 'angles',\n",
       " 'angle',\n",
       " 'small')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "02b05877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('supernova', 'explosions')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.intension(['Pulsar-driven Jets in Supernov...', 'Near-Earth Supernova Explosion...'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67fad94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Pulsar-driven Jets in Supernov...',\n",
       " 'Near-Earth Supernova Explosion...',\n",
       " 'Impact of sterile neutrino dar...')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.extension(['supernova'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dbfc8e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Pulsar-driven Jets in Supernov...', 'Near-Earth Supernova Explosion...')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.extension(['supernova', 'explosions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ceec299e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context == context.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7b222b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
